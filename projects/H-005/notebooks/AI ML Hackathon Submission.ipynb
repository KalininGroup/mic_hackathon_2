{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7f371ca-6c7d-4eee-b9bd-2f4a30bce8e1",
   "metadata": {},
   "source": [
    "# Towards Automated Materials Analysis: Deep Learning Denoising and Phase Identification from 4D-STEM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da49637e-baf4-4847-98d8-0bfbcbb3dac1",
   "metadata": {},
   "source": [
    "# 1. Dataset Curation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca15ee61-71fb-42cf-ac52-51242f4db803",
   "metadata": {},
   "source": [
    "## 1.1 Generation of clean image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5876e08f-81c4-4248-afdd-ae7f0789a39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage.draw import disk\n",
    "from pymatgen.ext.matproj import MPRester\n",
    "from pymatgen.symmetry.analyzer import SpacegroupAnalyzer\n",
    "from tqdm import tqdm\n",
    "import py4DSTEM\n",
    "import signal\n",
    "\n",
    "# --- Timeout setup ---\n",
    "class TimeoutException(Exception):\n",
    "    pass\n",
    " \n",
    "def timeout_handler(signum, frame):\n",
    "    raise TimeoutException()\n",
    "\n",
    "signal.signal(signal.SIGALRM, timeout_handler)\n",
    "\n",
    "# --- Configuration ---\n",
    "API_KEY = \"Kg3Lv1IRFzRaKbh0GrkTiJ8dZ9d5hPiG\"\n",
    "csv_path = \"/Users/ethan/Desktop/Materials Simulation MPhil Project/table_export_cubic.csv\" and \"/Users/ethan/Desktop/Materials Simulation MPhil Project/table_export_hcp.csv\"\n",
    "image_size = 256\n",
    "radius = 2\n",
    "output_dir = \"/Users/ethan/Desktop/Materials Simulation MPhil Project/Generated DPs Clean x\"\n",
    "checkpoint_file = \"/Users/ethan/Desktop/Materials Simulation MPhil Project/checkpoint x.txt\"\n",
    "timeout_log_file = \"/Users/ethan/Desktop/Materials Simulation MPhil Project/skipped_timeout_log x.txt\"\n",
    "redo_all = False\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --- ZA generator ---\n",
    "def ZA_list(max_index):\n",
    "    from itertools import product\n",
    "    ZAs = []\n",
    "    for h, k, l in product(range(-max_index, max_index+1), repeat=3):\n",
    "        if [h, k, l] != [0, 0, 0]:\n",
    "            ZAs.append([h, k, l])\n",
    "    return ZAs\n",
    "\n",
    "# --- Bravais type determination ---\n",
    "def get_bravais_type(structure):\n",
    "    analyzer = SpacegroupAnalyzer(structure)\n",
    "    lattice_type = analyzer.get_lattice_type().lower()\n",
    "    if \"face\" in lattice_type:\n",
    "        return \"fcc\"\n",
    "    elif \"body\" in lattice_type:\n",
    "        return \"bcc\"\n",
    "    elif \"primitive\" in lattice_type:\n",
    "        return \"sc\"    \n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# --- Selection rule ---\n",
    "def selection_multiplier(h, k, l, bravais_type):\n",
    "    if bravais_type == \"fcc\":\n",
    "        return 1 if (h % 2 == k % 2 == l % 2) else 0\n",
    "    elif bravais_type == \"bcc\":\n",
    "        return 1 if (h + k + l) % 2 == 0 else 0\n",
    "    elif bravais_type == \"sc\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# --- Load CSV and checkpoint ---\n",
    "df = pd.read_csv(csv_path)\n",
    "ZAs = ZA_list(2)\n",
    "done_set = set()\n",
    "if not redo_all and os.path.exists(checkpoint_file):\n",
    "    with open(checkpoint_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            done_set.add(line.strip())\n",
    "\n",
    "# --- Main loop ---\n",
    "with MPRester(API_KEY) as m, tqdm(total=len(df) * len(ZAs), desc=\"Generating DPs\", unit=\"DP\") as pbar:\n",
    "    for _, row in df.iterrows():\n",
    "        mp_id = row[\"Material ID\"]\n",
    "        formula = row[\"Formula\"]\n",
    "\n",
    "        try:\n",
    "            structure = m.get_structure_by_material_id(mp_id)\n",
    "            bravais_type = get_bravais_type(structure)\n",
    "            Material = py4DSTEM.process.diffraction.Crystal.from_pymatgen_structure(structure)\n",
    "            Material.calculate_dynamical_structure_factors(100e3, \"WK-CP\", k_max=4.0, thermal_sigma=0.08)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {mp_id}: {e}\")\n",
    "            pbar.update(len(ZAs))\n",
    "            continue\n",
    "\n",
    "        for ZA in ZAs:\n",
    "            tag = f\"{formula.replace(' ', '')}_{mp_id}_ZA_{ZA[0]}{ZA[1]}{ZA[2]}\"\n",
    "            if not redo_all and tag in done_set:\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                signal.alarm(120)  # 2-minute timeout\n",
    "                beams = Material.generate_diffraction_pattern(zone_axis_lattice=ZA, k_max=2)\n",
    "                pattern = Material.generate_dynamical_diffraction_pattern(beams=beams, thickness=10.0, zone_axis_lattice=ZA)\n",
    "                signal.alarm(0)\n",
    "\n",
    "                h, k, l = np.round(pattern.data[\"h\"]).astype(int), np.round(pattern.data[\"k\"]).astype(int), np.round(pattern.data[\"l\"]).astype(int)\n",
    "                multipliers = np.array([selection_multiplier(hi, ki, li, bravais_type) for hi, ki, li in zip(h, k, l)])\n",
    "                mask = multipliers > 0\n",
    "                pattern.data = pattern.data[mask]\n",
    "                intensity = pattern.data[\"intensity\"] * multipliers[mask]\n",
    "                pattern.data = pattern.data[intensity > 1e-5]\n",
    "                intensity = intensity[intensity > 1e-5]\n",
    "\n",
    "                qx = pattern.data[\"qx\"]\n",
    "                qy = pattern.data[\"qy\"]\n",
    "                qx_norm = ((qx - qx.min()) / (qx.max() - qx.min()) * (image_size - 1)).astype(int)\n",
    "                qy_norm = ((qy - qy.min()) / (qy.max() - qy.min()) * (image_size - 1)).astype(int)\n",
    "\n",
    "                image = np.zeros((image_size, image_size))\n",
    "                for x, y, I in zip(qx_norm, qy_norm, intensity):\n",
    "                    rr, cc = disk((y, x), radius, shape=image.shape)\n",
    "                    image[rr, cc] += 1e8 * I\n",
    "\n",
    "                clear_path = os.path.join(output_dir, f\"{tag}_clear.png\")\n",
    "                plt.imsave(clear_path, np.log1p(image), cmap=\"gray\")\n",
    "\n",
    "                with open(checkpoint_file, \"a\") as f:\n",
    "                    f.write(tag + \"\\n\")\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "            except TimeoutException:\n",
    "                msg = f\"Timeout on {mp_id} ZA={ZA}. Skipping...\\n\"\n",
    "                print(msg.strip())\n",
    "                with open(timeout_log_file, \"a\") as f:\n",
    "                    f.write(msg)\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error for {mp_id} ZA={ZA}: {e}\")\n",
    "                signal.alarm(0)\n",
    "                pbar.update(1)\n",
    "\n",
    "print(\"All DPs generated and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ff5027-b7ef-4211-b4cb-540e37370e26",
   "metadata": {},
   "source": [
    "## 1.2 Generation of noisy image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e139febd-025c-4848-9bba-c5aadec3d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.signal import convolve2d       # for streaks\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import blob_log      # for spot dimming\n",
    "\n",
    "\n",
    "# ───────────────────── CONTROL CENTRE ──────────────────────────────────────\n",
    "\n",
    "# Paths\n",
    "CLEAN_DIR = \"/Users/ethan/Desktop/Materials Simulation MPhil Project/Generated DPs Clean 3\"\n",
    "NOISY_DIR = \"/Users/ethan/Desktop/Materials Simulation MPhil Project/Generated DPs Noisy 10\"\n",
    "\n",
    "# Max Images\n",
    "MAX_IMAGES = None\n",
    "\n",
    "# Randomness\n",
    "RANDOM_SEED = 12345\n",
    "N_PREVIEW   = 10\n",
    "\n",
    "# Global toggles\n",
    "USE_LOG         = False   # linear scaling – like your example image\n",
    "USE_HALO        = True    # apply halo\n",
    "USE_SALT_PEPPER = Falase   # SP noise off for now\n",
    "USE_DIM_SPOTS   = True    # random spot dimming\n",
    "\n",
    "# Core noise parameters\n",
    "BACKGROUND_WEIGHT      = 0.3    # mostly signal, some radial background\n",
    "COUNTS_PER_PROBE       = 100    # electron counts scale\n",
    "INTENSITY_COEFFICIENT  = 10     # overall brightness\n",
    "\n",
    "# Halo parameters\n",
    "HALO_STRENGTH          = 1.5\n",
    "HALO_DECAY             = 1.5\n",
    "HALO_R_FLAT            = 10\n",
    "\n",
    "# Detector blur – sets spot size / faintness\n",
    "BLUR_SIGMA             = 1.4\n",
    "\n",
    "# Salt & pepper parameters\n",
    "SP_AMOUNT              = 0.5\n",
    "SP_SMOOTH              = 0.5\n",
    "SALT_VS_PEPPER         = 0.5\n",
    "\n",
    "# Streak parameters (000 streak / motion blur)\n",
    "USE_STREAKS       = True     # master on/off\n",
    "STREAK_PROB       = 0.4      # probability a DP gets a streak\n",
    "STREAK_RADIUS     = 18       # radius (pixels) around 000 affected\n",
    "MOTION_LEN        = 7        # diagonal kernel length\n",
    "MOTION_STRENGTH   = 0.6      # blend between original / streaked in disk\n",
    "\n",
    "# Central bloom / saturation for 000\n",
    "USE_CENTRAL_BLOOM   = True   # soften / saturate the central spot region\n",
    "BLOOM_RADIUS        = HALO_R_FLAT # pixels around centre to soften\n",
    "BLOOM_SIGMA         = 2    # blur strength inside bloom disc\n",
    "BLOOM_ATTENUATION   = 1   # 0–1: lower = darker centre after bloom\n",
    "\n",
    "# Beam stop / central block \n",
    "BLOCK_PROB             = 0.2\n",
    "BLOCK_RADIUS           = 20\n",
    "\n",
    "# Spot dimming parameters\n",
    "SPOT_P_DIM             = 0.3\n",
    "SPOT_MAX_SPOTS         = 10\n",
    "SPOT_DIM_RANGE         = (0.35, 0.7)\n",
    "SPOT_MIN_SIGMA         = 1.0\n",
    "SPOT_MAX_SIGMA         = 4.0\n",
    "SPOT_NUM_SIGMA         = 10\n",
    "SPOT_THRESHOLD         = 0.03\n",
    "SPOT_AVOID_CENTER_EXTRA = 5.0\n",
    "\n",
    "\n",
    "# ───────────────────── CORE NOISE MODEL ────────────────────────────────────\n",
    "\n",
    "def add_poisson_background_noise(\n",
    "    dp_stack,\n",
    "    background_weight,\n",
    "    counts_per_probe,\n",
    "    intensity_coefficient,\n",
    "    add_halo,\n",
    "    halo_strength,\n",
    "    halo_decay,\n",
    "    r_flat,\n",
    "    blur_sigma,\n",
    "    add_salt_pepper,\n",
    "    sp_amount,\n",
    "    sp_smooth,\n",
    "    salt_vs_pepper,\n",
    "    use_streaks,\n",
    "    streak_prob,\n",
    "    streak_radius,\n",
    "    motion_len,\n",
    "    motion_strength,\n",
    "    use_central_bloom,\n",
    "    bloom_radius,\n",
    "    bloom_sigma,\n",
    "    bloom_attenuation,\n",
    "    rng\n",
    "):\n",
    "    \"\"\"\n",
    "    Core noise model:\n",
    "      - optional halo on the signal\n",
    "      - radial background mix\n",
    "      - Poisson sampling\n",
    "      - Gaussian PSF blur\n",
    "      - optional 000 streak via diagonal motion blur in central disk\n",
    "      - optional central bloom (local blur + attenuation in centre)\n",
    "      - optional salt & pepper\n",
    "\n",
    "    All behaviour is determined by the arguments (which come from CONTROL CENTRE).\n",
    "    Returns *linear* intensities (not scaled to 0–1).\n",
    "    \"\"\"\n",
    "    N, H, W = dp_stack.shape\n",
    "    noisy_stack = np.zeros_like(dp_stack, dtype=np.float32)\n",
    "\n",
    "    # 1) build the radial background once\n",
    "    qx = np.fft.fftfreq(H); qy = np.fft.fftfreq(W)\n",
    "    qyA, qxA = np.meshgrid(qy, qx)\n",
    "    qxA, qyA = np.fft.fftshift(qxA), np.fft.fftshift(qyA)\n",
    "    r2 = qxA**2 + qyA**2\n",
    "    radial_scale = 1e-2\n",
    "    im_bg = 1.0 / (1 + r2 / radial_scale**2)\n",
    "    im_bg /= im_bg.sum()\n",
    "\n",
    "    # 2) coordinates and optional halo mask\n",
    "    Y, X = np.indices((H, W))\n",
    "    cy, cx = H//2, W//2\n",
    "    R = np.sqrt((X - cx)**2 + (Y - cy)**2)\n",
    "    if add_halo:\n",
    "        halo = np.exp(-R / halo_decay)\n",
    "        halo[R < r_flat] = 1.0\n",
    "        halo /= halo.max()\n",
    "    else:\n",
    "        halo = None\n",
    "\n",
    "    # 3) motion-blur kernel & streak mask for 000 streak\n",
    "    if use_streaks and motion_len > 1 and motion_strength > 0:\n",
    "        k = np.zeros((motion_len, motion_len), dtype=np.float32)\n",
    "        np.fill_diagonal(k, 1.0)\n",
    "        k /= k.sum()\n",
    "        streak_mask = (X - cx)**2 + (Y - cy)**2 <= streak_radius**2\n",
    "    else:\n",
    "        k = None\n",
    "        streak_mask = None\n",
    "\n",
    "    # 4) central bloom mask\n",
    "    if use_central_bloom and bloom_radius > 0:\n",
    "        bloom_mask = (X - cx)**2 + (Y - cy)**2 <= bloom_radius**2\n",
    "    else:\n",
    "        bloom_mask = None\n",
    "\n",
    "    for i in tqdm(range(N), desc=\"Adding noise\"):\n",
    "        frame = dp_stack[i].astype(np.float32).copy()\n",
    "\n",
    "        # halo on the signal\n",
    "        if halo is not None:\n",
    "            frame = frame + halo_strength * frame.max() * halo\n",
    "\n",
    "        # mix + poisson + scale\n",
    "        mixed = (1 - background_weight) * frame + background_weight * im_bg\n",
    "        noisy = rng.poisson(mixed * counts_per_probe) / counts_per_probe\n",
    "        noisy *= intensity_coefficient\n",
    "\n",
    "        # blur (PSF)\n",
    "        noisy = gaussian_filter(noisy, sigma=blur_sigma)\n",
    "\n",
    "        # optional 000 streak\n",
    "        if k is not None and streak_mask is not None and rng.random() < streak_prob:\n",
    "            blurred_motion = convolve2d(noisy, k, mode=\"same\", boundary=\"symm\")\n",
    "            noisy_streaked = noisy.copy()\n",
    "            noisy_streaked[streak_mask] = (\n",
    "                (1.0 - motion_strength) * noisy[streak_mask]\n",
    "                + motion_strength * blurred_motion[streak_mask]\n",
    "            )\n",
    "            noisy = noisy_streaked\n",
    "\n",
    "        # optional central bloom / saturation (local blur + attenuation)\n",
    "        if bloom_mask is not None:\n",
    "            centre_only = noisy * bloom_mask\n",
    "            blurred_centre = gaussian_filter(centre_only, sigma=bloom_sigma)\n",
    "            blended = (\n",
    "                bloom_attenuation * blurred_centre +\n",
    "                (1.0 - bloom_attenuation) * noisy\n",
    "            )\n",
    "            noisy[bloom_mask] = blended[bloom_mask]\n",
    "\n",
    "        # optional salt & pepper\n",
    "        if add_salt_pepper and sp_amount > 0:\n",
    "            num_s = int(sp_amount * H * W * salt_vs_pepper)\n",
    "            num_p = int(sp_amount * H * W * (1.0 - salt_vs_pepper))\n",
    "\n",
    "            if num_s > 0 or num_p > 0:\n",
    "                med = float(np.median(noisy))\n",
    "\n",
    "                if num_s > 0:\n",
    "                    salt_idx = (\n",
    "                        rng.integers(0, H, num_s),\n",
    "                        rng.integers(0, W, num_s)\n",
    "                    )\n",
    "                    noisy[salt_idx] = med * 1.3\n",
    "\n",
    "                if num_p > 0:\n",
    "                    pepper_idx = (\n",
    "                        rng.integers(0, H, num_p),\n",
    "                        rng.integers(0, W, num_p)\n",
    "                    )\n",
    "                    noisy[pepper_idx] = med * 0.7\n",
    "\n",
    "                noisy = gaussian_filter(noisy, sigma=sp_smooth)\n",
    "\n",
    "        noisy_stack[i] = noisy.astype(np.float32)\n",
    "\n",
    "    return noisy_stack\n",
    "\n",
    "\n",
    "# ───────────────────── CENTRAL BLOCK ───────────────────────────────────────\n",
    "\n",
    "def block_center(img, radius):\n",
    "    \"\"\"Zero‐out a disk of given radius at the centre.\"\"\"\n",
    "    H, W = img.shape\n",
    "    cy, cx = H//2, W//2\n",
    "    Y, X = np.ogrid[:H, :W]\n",
    "    mask = (X - cx)**2 + (Y - cy)**2 <= radius**2\n",
    "    out = img.copy()\n",
    "    out[mask] = 0.0\n",
    "    return out\n",
    "\n",
    "\n",
    "# ───────────────────── BLOB-BASED SPOT DIMMING ─────────────────────────────\n",
    "\n",
    "def dim_spots(\n",
    "    img: np.ndarray,\n",
    "    p_dim: float,\n",
    "    max_spots: int,\n",
    "    dim_range,\n",
    "    min_sigma: float,\n",
    "    max_sigma: float,\n",
    "    num_sigma: int,\n",
    "    threshold: float,\n",
    "    avoid_center: float,\n",
    "    rng\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Detect bright blobs and randomly dim a subset outside a central radius.\n",
    "    Assumes img is scaled to ~0–1 (log or linear normalised).\n",
    "    All control comes from arguments (which are set in CONTROL CENTRE).\n",
    "    \"\"\"\n",
    "    H, W = img.shape\n",
    "    cy, cx = H / 2.0, W / 2.0\n",
    "\n",
    "    blobs = blob_log(\n",
    "        img,\n",
    "        min_sigma=min_sigma,\n",
    "        max_sigma=max_sigma,\n",
    "        num_sigma=num_sigma,\n",
    "        threshold=threshold\n",
    "    )\n",
    "\n",
    "    if blobs.size:\n",
    "        dists = np.hypot(blobs[:, 0] - cy, blobs[:, 1] - cx)\n",
    "        candidates = blobs[dists > avoid_center]\n",
    "    else:\n",
    "        candidates = np.empty((0, 3))\n",
    "\n",
    "    out = img.copy()\n",
    "\n",
    "    if candidates.size:\n",
    "        keep = rng.random(len(candidates)) < p_dim\n",
    "        chosen = candidates[keep]\n",
    "        if len(chosen) > max_spots:\n",
    "            chosen = chosen[rng.choice(len(chosen), max_spots, replace=False)]\n",
    "\n",
    "        yy, xx = np.ogrid[:H, :W]\n",
    "        for y, x, sigma in chosen:\n",
    "            radius = float(sigma) * np.sqrt(2.0)\n",
    "            att = float(rng.uniform(dim_range[0], dim_range[1]))\n",
    "            mask = (yy - y)**2 + (xx - x)**2 <= radius**2\n",
    "            out[mask] *= att\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ───────────────────── MAIN PIPELINE ───────────────────────────────────────\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(NOISY_DIR, exist_ok=True)\n",
    "\n",
    "    # 1) load clean stack (0–1)\n",
    "    clean_files = sorted(f for f in os.listdir(CLEAN_DIR) if f.endswith(\"_clear.png\"))\n",
    "\n",
    "    if MAX_IMAGES is not None:\n",
    "        clean_files = clean_files[:MAX_IMAGES]\n",
    "\n",
    "    print(f\"Processing {len(clean_files)} images from '{CLEAN_DIR}'\")\n",
    "\n",
    "    dp_stack = np.stack([\n",
    "        np.array(\n",
    "            Image.open(os.path.join(CLEAN_DIR, f)).convert(\"L\"),\n",
    "            dtype=np.float32\n",
    "        ) / 255.0\n",
    "        for f in tqdm(clean_files, desc=\"Loading clean images\")\n",
    "    ])\n",
    "\n",
    "    rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "    # 2) add Poisson + radial background + blur (+ halo / streaks / bloom / S&P if toggled on)\n",
    "    noisy_stack = add_poisson_background_noise(\n",
    "        dp_stack=dp_stack,\n",
    "        background_weight=BACKGROUND_WEIGHT,\n",
    "        counts_per_probe=COUNTS_PER_PROBE,\n",
    "        intensity_coefficient=INTENSITY_COEFFICIENT,\n",
    "        add_halo=USE_HALO,\n",
    "        halo_strength=HALO_STRENGTH,\n",
    "        halo_decay=HALO_DECAY,\n",
    "        r_flat=HALO_R_FLAT,\n",
    "        blur_sigma=BLUR_SIGMA,\n",
    "        add_salt_pepper=USE_SALT_PEPPER,\n",
    "        sp_amount=SP_AMOUNT,\n",
    "        sp_smooth=SP_SMOOTH,\n",
    "        salt_vs_pepper=SALT_VS_PEPPER,\n",
    "        use_streaks=USE_STREAKS,\n",
    "        streak_prob=STREAK_PROB,\n",
    "        streak_radius=STREAK_RADIUS,\n",
    "        motion_len=MOTION_LEN,\n",
    "        motion_strength=MOTION_STRENGTH,\n",
    "        use_central_bloom=USE_CENTRAL_BLOOM,\n",
    "        bloom_radius=BLOOM_RADIUS,\n",
    "        bloom_sigma=BLOOM_SIGMA,\n",
    "        bloom_attenuation=BLOOM_ATTENUATION,\n",
    "        rng=rng\n",
    "    )\n",
    "\n",
    "    # 3) randomly block centre on some patterns (beam stop / saturation)\n",
    "    for i in range(len(noisy_stack)):\n",
    "        if rng.random() < BLOCK_PROB:\n",
    "            noisy_stack[i] = block_center(noisy_stack[i], BLOCK_RADIUS)\n",
    "\n",
    "    # 4) normalisation step with log optional\n",
    "    if USE_LOG:\n",
    "        lg_stack = np.log1p(noisy_stack)\n",
    "        G = float(lg_stack.max())\n",
    "        norm_stack = lg_stack / (G + 1e-12)\n",
    "    else:\n",
    "        G = float(noisy_stack.max())\n",
    "        norm_stack = noisy_stack / (G + 1e-12)\n",
    "\n",
    "    # 5) optional blob-based spot dimming on the normalised images\n",
    "    if USE_DIM_SPOTS:\n",
    "        dimmed_stack = np.zeros_like(norm_stack, dtype=np.float32)\n",
    "        avoid_center = BLOCK_RADIUS + SPOT_AVOID_CENTER_EXTRA\n",
    "        for i in tqdm(range(len(norm_stack)), desc=\"Dimming spots\"):\n",
    "            dimmed_stack[i] = dim_spots(\n",
    "                img=norm_stack[i],\n",
    "                p_dim=SPOT_P_DIM,\n",
    "                max_spots=SPOT_MAX_SPOTS,\n",
    "                dim_range=SPOT_DIM_RANGE,\n",
    "                min_sigma=SPOT_MIN_SIGMA,\n",
    "                max_sigma=SPOT_MAX_SIGMA,\n",
    "                num_sigma=SPOT_NUM_SIGMA,\n",
    "                threshold=SPOT_THRESHOLD,\n",
    "                avoid_center=avoid_center,\n",
    "                rng=rng\n",
    "            )\n",
    "        final_stack = dimmed_stack\n",
    "    else:\n",
    "        final_stack = norm_stack\n",
    "\n",
    "    # 6) save out final images\n",
    "    for fname, im in zip(clean_files, final_stack):\n",
    "        outname = fname.replace(\"_clear.png\", \"_noisy.png\")\n",
    "        img8 = (np.clip(im, 0, 1) * 255).astype(np.uint8)\n",
    "        Image.fromarray(img8).save(os.path.join(NOISY_DIR, outname))\n",
    "\n",
    "    # 7) preview\n",
    "    fig, axs = plt.subplots(1, N_PREVIEW, figsize=(3 * N_PREVIEW, 3))\n",
    "    for i in range(min(N_PREVIEW, final_stack.shape[0])):\n",
    "        axs[i].imshow(final_stack[i], cmap=\"gray\", vmin=0, vmax=1)\n",
    "        axs[i].set_title(f\"Noisy #{i+1}\")\n",
    "        axs[i].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e34a325-4a83-439e-a983-f782e7f32fa4",
   "metadata": {},
   "source": [
    "# 2. Neural Network Training (Dense U-Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4141e63-64a7-45fd-917d-c935fa7a5562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:\n",
      "   epochs         = 89\n",
      "   batch_size     = 8\n",
      "   learning_rate  = 1e-05\n",
      "   max_train_imgs = 30000\n",
      "   checkpoint_dir = /Users/ethan/Desktop/Materials Simulation MPhil Project/checkpoints\n",
      "   early stopping patience = 20\n",
      "\n",
      "Using device: mps\n",
      "\n",
      "Found 28139 matched clean/noisy pairs.\n",
      "\n",
      "Train size: 22511, Val size: 5628\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Use previous checkpoint? (Y/N):  y\n",
      "   Enter version to resume (e.g. 27):  72\n",
      "   Overwrite this same version? (Y/N):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumed v72 at epoch 89, will save v72\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "# ─── MODEL DEFINITIONS (RDUNet-style) ────────────────────────────────────────\n",
    "\n",
    "@torch.no_grad()\n",
    "def init_weights(init_type='xavier'):\n",
    "    if init_type == 'xavier':\n",
    "        init = nn.init.xavier_normal_\n",
    "    elif init_type == 'he':\n",
    "        init = nn.init.kaiming_normal_\n",
    "    else:\n",
    "        init = nn.init.orthogonal_\n",
    "\n",
    "    def initializer(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv2d') != -1:\n",
    "            init(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        elif classname.find('BatchNorm') != -1:\n",
    "            nn.init.normal_(m.weight, 1.0, 0.01)\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "    return initializer\n",
    "\n",
    "\n",
    "class ResidualDenseBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    RD block: small dense block with local residual.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, growth_rate=32, num_layers=4):\n",
    "        super().__init__()\n",
    "        self.in_ch = in_ch\n",
    "        self.growth_rate = growth_rate\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        layers = []\n",
    "        ch = in_ch\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(nn.Conv2d(ch, growth_rate, kernel_size=3, padding=1))\n",
    "            ch += growth_rate\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "        self.lrelu = nn.ReLU(inplace=True)\n",
    "        # compress back to in_ch\n",
    "        self.conv_1x1 = nn.Conv2d(ch, in_ch, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = [x]\n",
    "        for conv in self.layers:\n",
    "            out = conv(torch.cat(feats, dim=1))\n",
    "            out = self.lrelu(out)\n",
    "            feats.append(out)\n",
    "        out = torch.cat(feats, dim=1)\n",
    "        out = self.conv_1x1(out)\n",
    "        return x + out  # local residual\n",
    "\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder stage: RD blocks + strided conv downsampling.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, num_rdb=2, growth_rate=32):\n",
    "        super().__init__()\n",
    "        self.rdbs = nn.Sequential(*[\n",
    "            ResidualDenseBlock(in_ch, growth_rate=growth_rate)\n",
    "            for _ in range(num_rdb)\n",
    "        ])\n",
    "        self.down = nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.rdbs(x)\n",
    "        skip = x\n",
    "        x = self.down(x)\n",
    "        return x, skip\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder stage: upsample + skip concat + RD blocks.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, num_rdb=2, growth_rate=32):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2)\n",
    "        self.reduce = nn.Conv2d(out_ch * 2, out_ch, kernel_size=1)\n",
    "        self.rdbs = nn.Sequential(*[\n",
    "            ResidualDenseBlock(out_ch, growth_rate=growth_rate)\n",
    "            for _ in range(num_rdb)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.up(x)\n",
    "        # in case of 1-pixel mismatches, center-crop skip\n",
    "        if x.shape[-2:] != skip.shape[-2:]:\n",
    "            dh = skip.shape[-2] - x.shape[-2]\n",
    "            dw = skip.shape[-1] - x.shape[-1]\n",
    "            top = max(dh // 2, 0)\n",
    "            left = max(dw // 2, 0)\n",
    "            skip = skip[..., top:top + x.shape[-2], left:left + x.shape[-1]]\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.reduce(x)\n",
    "        x = self.rdbs(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RDUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    RDUNet-style residual dense U-Net for denoising.\n",
    "\n",
    "    - channels: 1 for grayscale DPs\n",
    "    - forward(x) returns the *denoised* image using global residual:\n",
    "          denoised = x - F(x)\n",
    "      where F(x) is the predicted noise.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 channels=1,\n",
    "                 base_ch=64,\n",
    "                 growth_rate=32,\n",
    "                 num_rdb=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.head = nn.Conv2d(channels, base_ch, kernel_size=3, padding=1)\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = EncoderBlock(base_ch,   base_ch * 2,\n",
    "                                 num_rdb=num_rdb, growth_rate=growth_rate)\n",
    "        self.enc2 = EncoderBlock(base_ch*2, base_ch * 4,\n",
    "                                 num_rdb=num_rdb, growth_rate=growth_rate)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            ResidualDenseBlock(base_ch * 4, growth_rate=growth_rate),\n",
    "            ResidualDenseBlock(base_ch * 4, growth_rate=growth_rate),\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.dec2 = DecoderBlock(base_ch * 4, base_ch * 2,\n",
    "                                 num_rdb=num_rdb, growth_rate=growth_rate)\n",
    "        self.dec1 = DecoderBlock(base_ch * 2, base_ch,\n",
    "                                 num_rdb=num_rdb, growth_rate=growth_rate)\n",
    "\n",
    "        self.tail = nn.Conv2d(base_ch, channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        inp = x\n",
    "\n",
    "        x = self.head(x)\n",
    "\n",
    "        x, skip1 = self.enc1(x)   # 1st encoder stage\n",
    "        x, skip2 = self.enc2(x)   # 2nd encoder stage\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        x = self.dec2(x, skip2)\n",
    "        x = self.dec1(x, skip1)\n",
    "\n",
    "        noise = self.tail(x)\n",
    "        denoised = inp - noise     # global residual: predict noise\n",
    "        return denoised\n",
    "\n",
    "\n",
    "# ─── 0) HYPERPARAMETERS & PATHS ─────────────────────────────────────────────\n",
    "\n",
    "clean_dir       = \"/Users/ethan/Desktop/Materials Simulation MPhil Project/Generated DPs Clean 3\"\n",
    "noisy_dir       = \"/Users/ethan/Desktop/Materials Simulation MPhil Project/Generated DPs Noisy 9\"\n",
    "\n",
    "epochs          = 89\n",
    "batch_size      = 8\n",
    "lr              = 1e-5\n",
    "max_train_imgs  = 30000\n",
    "patience        = 20  # early stopping\n",
    "\n",
    "checkpoint_dir  = \"/Users/ethan/Desktop/Materials Simulation MPhil Project/checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "print(\"Hyperparameters:\")\n",
    "print(f\"   epochs         = {epochs}\")\n",
    "print(f\"   batch_size     = {batch_size}\")\n",
    "print(f\"   learning_rate  = {lr}\")\n",
    "print(f\"   max_train_imgs = {max_train_imgs}\")\n",
    "print(f\"   checkpoint_dir = {checkpoint_dir}\")\n",
    "print(f\"   early stopping patience = {patience}\\n\")\n",
    "\n",
    "\n",
    "# ─── 1) DEVICE ───────────────────────────────────────────────────────────────\n",
    "\n",
    "device = torch.device(\n",
    "    \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cuda\" if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using device: {device}\\n\")\n",
    "\n",
    "\n",
    "# ─── 2) CROP TO MULTIPLE OF 4 ────────────────────────────────────────────────\n",
    "\n",
    "class CenterCropToMultipleOf4:\n",
    "    def __call__(self, img):\n",
    "        # img is PIL Image (W, H)\n",
    "        w, h = img.size\n",
    "        new_h = h - (h % 4)\n",
    "        new_w = w - (w % 4)\n",
    "\n",
    "        left   = (w - new_w) // 2\n",
    "        top    = (h - new_h) // 2\n",
    "        right  = left + new_w\n",
    "        bottom = top + new_h\n",
    "\n",
    "        return img.crop((left, top, right, bottom))\n",
    "\n",
    "\n",
    "# ─── 3) PAIR CLEAN / NOISY FILES ─────────────────────────────────────────────\n",
    "\n",
    "def strip_suffix(fn):\n",
    "    return fn.replace(\"_clear.png\", \"\").replace(\"_noisy.png\", \"\")\n",
    "\n",
    "clean_files = sorted(f for f in os.listdir(clean_dir) if f.endswith(\".png\"))\n",
    "noisy_files = sorted(f for f in os.listdir(noisy_dir) if f.endswith(\".png\"))\n",
    "\n",
    "cb = {strip_suffix(f): f for f in clean_files}\n",
    "nb = {strip_suffix(f): f for f in noisy_files}\n",
    "keys = sorted(set(cb) & set(nb))\n",
    "\n",
    "clean_paths = [os.path.join(clean_dir, cb[k]) for k in keys]\n",
    "noisy_paths = [os.path.join(noisy_dir, nb[k]) for k in keys]\n",
    "\n",
    "print(f\"Found {len(keys)} matched clean/noisy pairs.\\n\")\n",
    "if len(keys) == 0:\n",
    "    raise RuntimeError(\"No matched clean/noisy PNG pairs found. Check your directories and filenames.\")\n",
    "\n",
    "\n",
    "# ─── 4) DATASET & DATALOADER ────────────────────────────────────────────────\n",
    "\n",
    "class DPDenoiseDataset(Dataset):\n",
    "    def __init__(self, noisy_paths, clean_paths, transform=None):\n",
    "        self.noisy = noisy_paths\n",
    "        self.clean = clean_paths\n",
    "        self.tf    = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.noisy)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        n = Image.open(self.noisy[idx]).convert(\"L\")\n",
    "        c = Image.open(self.clean[idx]).convert(\"L\")\n",
    "        if self.tf:\n",
    "            n = self.tf(n)\n",
    "            c = self.tf(c)\n",
    "        return n, c\n",
    "\n",
    "\n",
    "tfm = transforms.Compose([\n",
    "    CenterCropToMultipleOf4(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_n, val_n, train_c, val_c = train_test_split(\n",
    "    noisy_paths, clean_paths, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_n, train_c = train_n[:max_train_imgs], train_c[:max_train_imgs]\n",
    "\n",
    "train_ds = DPDenoiseDataset(train_n, train_c, tfm)\n",
    "val_ds   = DPDenoiseDataset(val_n,   val_c,   tfm)\n",
    "\n",
    "train_ld = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_ld   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Train size: {len(train_ds)}, Val size: {len(val_ds)}\\n\")\n",
    "\n",
    "\n",
    "# ─── 5) RDUNet MODEL ─────────────────────────────────────────────────────────\n",
    "\n",
    "model = RDUNet(channels=1, base_ch=64, growth_rate=32, num_rdb=2).to(device)\n",
    "model.apply(init_weights('xavier'))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "# ─── 6) CHECKPOINT HANDLING ──────────────────────────────────────────────────\n",
    "\n",
    "use_prev = input(\"Use previous checkpoint? (Y/N): \").strip().upper()\n",
    "if use_prev == \"Y\":\n",
    "    ver_prev = int(input(\"   Enter version to resume (e.g. 27): \").strip())\n",
    "    resume_path = os.path.join(checkpoint_dir, f\"dranet_checkpoint{ver_prev:02d}.pth\")\n",
    "    if not os.path.isfile(resume_path):\n",
    "        print(f\"Warning: {resume_path} not found → training from scratch.\\n\")\n",
    "        start_epoch, train_losses, val_losses = 1, [], []\n",
    "        ver_save = ver_prev\n",
    "        save_path = os.path.join(checkpoint_dir, f\"dranet_checkpoint{ver_save:02d}.pth\")\n",
    "    else:\n",
    "        overwrite = input(\"   Overwrite this same version? (Y/N): \").strip().upper()\n",
    "        ver_save = ver_prev if overwrite == \"Y\" else int(input(\"   Enter new save version: \").strip())\n",
    "        save_path = os.path.join(checkpoint_dir, f\"dranet_checkpoint{ver_save:02d}.pth\")\n",
    "\n",
    "        ck = torch.load(resume_path, map_location=device)\n",
    "        model.load_state_dict(ck['model_state_dict'], strict=False)\n",
    "        optimizer.load_state_dict(ck['optimizer_state_dict'])\n",
    "        start_epoch  = ck.get('epoch', 0) + 1\n",
    "        train_losses = ck.get('train_losses', [])\n",
    "        val_losses   = ck.get('val_losses',   [])\n",
    "        print(f\"Resumed v{ver_prev} at epoch {start_epoch-1}, will save v{ver_save}\\n\")\n",
    "else:\n",
    "    ver_save = int(input(\"   Enter initial save version (e.g. 01): \").strip())\n",
    "    save_path = os.path.join(checkpoint_dir, f\"dranet_checkpoint{ver_save:02d}.pth\")\n",
    "    start_epoch = 1\n",
    "    train_losses, val_losses = [], []\n",
    "    print(f\"Training from scratch → will save v{ver_save}\\n\")\n",
    "\n",
    "\n",
    "# ─── 7) TRAIN LOOP WITH EARLY STOPPING ──────────────────────────────────────\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs_no_improve = 0\n",
    "early_stop_triggered = False\n",
    "\n",
    "for ep in range(start_epoch, epochs + 1):\n",
    "    if early_stop_triggered:\n",
    "        print(f\"Early stopping triggered at epoch {ep-1}. Best val loss: {best_val_loss:.6f}\")\n",
    "        break\n",
    "\n",
    "    # — train —\n",
    "    model.train()\n",
    "    tL = 0.0\n",
    "    for noisy, clean in tqdm(train_ld, desc=f\"Train {ep}/{epochs}\"):\n",
    "        noisy, clean = noisy.to(device), clean.to(device)\n",
    "        den_pred = model(noisy)          # RDUNet outputs *denoised* image (x - noise)\n",
    "        loss     = criterion(den_pred, clean)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tL += loss.item()\n",
    "    tL /= len(train_ld)\n",
    "    train_losses.append(tL)\n",
    "\n",
    "    # — val —\n",
    "    model.eval()\n",
    "    vL = 0.0\n",
    "    with torch.no_grad():\n",
    "        for noisy, clean in val_ld:\n",
    "            noisy, clean = noisy.to(device), clean.to(device)\n",
    "            den_pred = model(noisy)\n",
    "            vL += criterion(den_pred, clean).item()\n",
    "    vL /= len(val_ld)\n",
    "    val_losses.append(vL)\n",
    "\n",
    "    print(f\"[Epoch {ep:03d}] Train L={tL:.6f}, Val L={vL:.6f}\")\n",
    "\n",
    "    # Early stopping logic\n",
    "    if vL < best_val_loss - 1e-6:\n",
    "        best_val_loss = vL\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"   No improvement for {epochs_no_improve}/{patience} epochs.\")\n",
    "        if epochs_no_improve >= patience:\n",
    "            early_stop_triggered = True\n",
    "\n",
    "    # Save checkpoint\n",
    "    torch.save({\n",
    "        'epoch':                ep,\n",
    "        'model_state_dict':     model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_losses':         train_losses,\n",
    "        'val_losses':           val_losses,\n",
    "    }, save_path)\n",
    "    if ep == epochs or early_stop_triggered:\n",
    "        print(f\"   Saved checkpoint: {save_path}\\n\")\n",
    "\n",
    "\n",
    "# ─── 8) FINAL LOSS PLOT ─────────────────────────────────────────────────────\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(range(1, len(train_losses)+1), train_losses, label=\"Train Loss\")\n",
    "plt.plot(range(1, len(val_losses)+1),   val_losses,   label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.title(f\"RDUNet Loss Curve (ckpt {ver_save:02d})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5850572-7fa1-4fde-a35a-217622b420c5",
   "metadata": {},
   "source": [
    "# 3. NMC 811 Evaluation (Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d851ec4-c37d-401f-96e7-da3b46832151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "\n",
      "Loading checkpoint /Users/ethan/Desktop/Materials Simulation MPhil Project/checkpoints/dranet_checkpoint72.pth\n",
      "Output directory: /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_1.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_2.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_3.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_4.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_5.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_6.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_7.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_8.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_9.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_10.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_11.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_12.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_13.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_14.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_15.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_16.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_17.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_18.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_19.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_20.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_21.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_22.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_23.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_24.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_25.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_26.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_27.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_28.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_29.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_30.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_31.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_32.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_33.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_34.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_35.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_36.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_37.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_38.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_39.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_40.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_41.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_42.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_43.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_44.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_45.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_46.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_47.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_48.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_49.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_50.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_51.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_52.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_53.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_54.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_55.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_56.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_57.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_58.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_59.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_60.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_61.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_62.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_63.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_64.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_65.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_66.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_67.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_68.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_69.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_70.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_71.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_72.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_73.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_74.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_75.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_76.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_77.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_78.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_79.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_80.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_81.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_82.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_83.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_84.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_85.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_86.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_87.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_88.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_89.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_90.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_91.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_92.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_93.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_94.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_95.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_96.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_97.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_98.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_99.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_100.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_101.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_102.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_103.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_104.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_105.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_106.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_107.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_108.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_109.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_110.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_111.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_112.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_113.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_114.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_115.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_116.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_117.png\n",
      "✓ saved /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/ckpt72_page_118.png\n",
      "✓ saved composite pages and per-panel images in /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Five-panel visualisation WITH coloured ring overlay\n",
    "(a) noisy\n",
    "(b) ring-masked noisy\n",
    "(c) log(ring)\n",
    "(d) denoised ring\n",
    "(e) log(denoised)\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  # kept for completeness\n",
    "from torchvision import transforms\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "\n",
    "# ───────────────────── MODEL DEFINITIONS (same RDUNet as training) ───────────\n",
    "\n",
    "class ResidualDenseBlock(nn.Module):\n",
    "    def __init__(self, in_ch, growth_rate=32, num_layers=4):\n",
    "        super().__init__()\n",
    "        self.in_ch = in_ch\n",
    "        layers = []\n",
    "        ch = in_ch\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(nn.Conv2d(ch, growth_rate, kernel_size=3, padding=1))\n",
    "            ch += growth_rate\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.lrelu = nn.ReLU(inplace=True)\n",
    "        self.conv_1x1 = nn.Conv2d(ch, in_ch, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = [x]\n",
    "        for conv in self.layers:\n",
    "            out = conv(torch.cat(feats, dim=1))\n",
    "            out = self.lrelu(out)\n",
    "            feats.append(out)\n",
    "        out = torch.cat(feats, dim=1)\n",
    "        out = self.conv_1x1(out)\n",
    "        return x + out\n",
    "\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, num_rdb=2, growth_rate=32):\n",
    "        super().__init__()\n",
    "        self.rdbs = nn.Sequential(*[\n",
    "            ResidualDenseBlock(in_ch, growth_rate=growth_rate)\n",
    "            for _ in range(num_rdb)\n",
    "        ])\n",
    "        self.down = nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.rdbs(x)\n",
    "        skip = x\n",
    "        x = self.down(x)\n",
    "        return x, skip\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, num_rdb=2, growth_rate=32):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2)\n",
    "        self.reduce = nn.Conv2d(out_ch * 2, out_ch, kernel_size=1)\n",
    "        self.rdbs = nn.Sequential(*[\n",
    "            ResidualDenseBlock(out_ch, growth_rate=growth_rate)\n",
    "            for _ in range(num_rdb)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.up(x)\n",
    "        if x.shape[-2:] != skip.shape[-2:]:\n",
    "            dh = skip.shape[-2] - x.shape[-2]\n",
    "            dw = skip.shape[-1] - x.shape[-1]\n",
    "            top = max(dh // 2, 0)\n",
    "            left = max(dw // 2, 0)\n",
    "            skip = skip[..., top:top + x.shape[-2], left:left + x.shape[-1]]\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.reduce(x)\n",
    "        x = self.rdbs(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RDUNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 channels=1,\n",
    "                 base_ch=64,\n",
    "                 growth_rate=32,\n",
    "                 num_rdb=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.head = nn.Conv2d(channels, base_ch, kernel_size=3, padding=1)\n",
    "\n",
    "        self.enc1 = EncoderBlock(base_ch,   base_ch * 2,\n",
    "                                 num_rdb=num_rdb, growth_rate=growth_rate)\n",
    "        self.enc2 = EncoderBlock(base_ch*2, base_ch * 4,\n",
    "                                 num_rdb=num_rdb, growth_rate=growth_rate)\n",
    "\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            ResidualDenseBlock(base_ch * 4, growth_rate=growth_rate),\n",
    "            ResidualDenseBlock(base_ch * 4, growth_rate=growth_rate),\n",
    "        )\n",
    "\n",
    "        self.dec2 = DecoderBlock(base_ch * 4, base_ch * 2,\n",
    "                                 num_rdb=num_rdb, growth_rate=growth_rate)\n",
    "        self.dec1 = DecoderBlock(base_ch * 2, base_ch,\n",
    "                                 num_rdb=num_rdb, growth_rate=growth_rate)\n",
    "\n",
    "        self.tail = nn.Conv2d(base_ch, channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        inp = x\n",
    "        x = self.head(x)\n",
    "        x, skip1 = self.enc1(x)\n",
    "        x, skip2 = self.enc2(x)\n",
    "        x = self.bottleneck(x)\n",
    "        x = self.dec2(x, skip2)\n",
    "        x = self.dec1(x, skip1)\n",
    "        noise = self.tail(x)\n",
    "        return inp - noise  # denoised DP (residual)\n",
    "\n",
    "\n",
    "# ───────────────────── CONFIG ─────────────────────\n",
    "\n",
    "ROOT      = Path(\"/Users/ethan/Desktop/Materials Simulation MPhil Project\")\n",
    "CHKPT_DIR = ROOT / \"checkpoints\"\n",
    "IMG_DIR   = ROOT / \"dpc_pixel\"\n",
    "FIG_ROOT  = ROOT / \"figures\"\n",
    "FIG_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CHKPTS       = [72]   \n",
    "PER_CKPT     = 588\n",
    "IMGS_PER_FIG = 5\n",
    "SEED         = 12345\n",
    "\n",
    "INNER_R = 0.05\n",
    "OUTER_R = 0.20\n",
    "RING_COLORS = dict(inner=\"blue\", outer=\"orange\")\n",
    "\n",
    "DEVICE = torch.device(\n",
    "    \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cuda\" if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "\n",
    "# ───────────────────── TRANSFORMS ─────────────────────\n",
    "\n",
    "class CenterCropToMultipleOf4:\n",
    "    def __call__(self, img):\n",
    "        w, h = img.size\n",
    "        new_h = h - (h % 4)\n",
    "        new_w = w - (w % 4)\n",
    "        left   = (w - new_w) // 2\n",
    "        top    = (h - new_h) // 2\n",
    "        right  = left + new_w\n",
    "        bottom = top + new_h\n",
    "        return img.crop((left, top, right, bottom))\n",
    "\n",
    "\n",
    "TFM = transforms.Compose([\n",
    "    CenterCropToMultipleOf4(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "# ───────────────────── UTILS ─────────────────────\n",
    "\n",
    "def load_gray(p: Path) -> torch.Tensor:\n",
    "    img = Image.open(p).convert(\"L\")\n",
    "    img = TFM(img)\n",
    "    return img.unsqueeze(0).to(DEVICE)  # 1×1×H×W\n",
    "\n",
    "\n",
    "def make_ring_mask(h, w, inner=INNER_R, outer=OUTER_R, device=\"cpu\"):\n",
    "    yy, xx = torch.meshgrid(\n",
    "        torch.arange(h, device=device),\n",
    "        torch.arange(w, device=device),\n",
    "        indexing=\"ij\"\n",
    "    )\n",
    "    cy, cx = h // 2, w // 2\n",
    "    rr2 = (yy - cy) ** 2 + (xx - cx) ** 2\n",
    "    rmin2 = (min(h, w) * inner) ** 2\n",
    "    rmax2 = (min(h, w) * outer) ** 2\n",
    "    return ((rr2 > rmin2) & (rr2 < rmax2)).float()  # H×W\n",
    "\n",
    "\n",
    "def to_log(arr, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Safe log transform:\n",
    "    - clamp negatives to 0\n",
    "    - add eps to avoid log(0)\n",
    "    - min-max normalise to [0, 1]\n",
    "    \"\"\"\n",
    "    arr = np.asarray(arr)\n",
    "    arr = np.maximum(arr, 0.0)\n",
    "    lg = np.log(arr + eps)\n",
    "    lg_min = lg.min()\n",
    "    lg_max = lg.max()\n",
    "    if lg_max - lg_min < 1e-12:\n",
    "        return np.zeros_like(lg)\n",
    "    return (lg - lg_min) / (lg_max - lg_min)\n",
    "\n",
    "\n",
    "def draw_ring(ax, h, w):\n",
    "    cy, cx = h / 2, w / 2\n",
    "    for r, col in ((INNER_R, RING_COLORS[\"inner\"]),\n",
    "                   (OUTER_R, RING_COLORS[\"outer\"])):\n",
    "        circ = Circle(\n",
    "            (cx, cy),\n",
    "            r * min(h, w),\n",
    "            fill=False,\n",
    "            color=col,\n",
    "            linewidth=1.2\n",
    "        )\n",
    "        ax.add_patch(circ)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def denoise_ring(model, img_path: Path):\n",
    "    noisy = load_gray(img_path)          # 1×1×H×W (0–1 from ToTensor)\n",
    "    H, W = noisy.shape[-2:]\n",
    "    mask = make_ring_mask(H, W, device=noisy.device)   # H×W\n",
    "    mask_4d = mask.unsqueeze(0).unsqueeze(0)           # 1×1×H×W\n",
    "\n",
    "    # Section out only the ring\n",
    "    noisy_ring = noisy * mask_4d\n",
    "\n",
    "    # RDUNet residual denoising on the ring only\n",
    "    den = model(noisy_ring)\n",
    "\n",
    "    # Clamp to [0, 1] to avoid negative intensities before log transform\n",
    "    den = den.clamp(min=0.0, max=1.0) * mask_4d\n",
    "\n",
    "    return (\n",
    "        noisy.squeeze().cpu().numpy(),        # full noisy DP\n",
    "        noisy_ring.squeeze().cpu().numpy(),   # ring-masked noisy DP\n",
    "        den.squeeze().cpu().numpy()           # ring-masked denoised DP\n",
    "    )\n",
    "\n",
    "\n",
    "# ───────────────────── MAIN ─────────────────────\n",
    "\n",
    "def main():\n",
    "    imgs = sorted([\n",
    "        p for p in IMG_DIR.iterdir()\n",
    "        if p.suffix.lower() in {\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\"}\n",
    "    ])\n",
    "    assert imgs, f\"No images found in {IMG_DIR}\"\n",
    "\n",
    "    random.seed(SEED)\n",
    "\n",
    "    # Ring labels like \"8-25\" for INNER_R=0.08, OUTER_R=0.25\n",
    "    inner_pct = int(round(INNER_R * 100))\n",
    "    outer_pct = int(round(OUTER_R * 100))\n",
    "\n",
    "    for ver in CHKPTS:\n",
    "        # Folder name: \"69 denoise 8-25\"\n",
    "        out_dir = FIG_ROOT / f\"{ver:02d} denoise {inner_pct}-{outer_pct}\"\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        ckpt = CHKPT_DIR / f\"dranet_checkpoint{ver:02d}.pth\"\n",
    "        if not ckpt.exists():\n",
    "            print(\"skip\", ckpt)\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nLoading checkpoint {ckpt}\")\n",
    "        print(f\"Output directory: {out_dir}\")\n",
    "        model = RDUNet(channels=1, base_ch=64, growth_rate=32, num_rdb=2).to(DEVICE)\n",
    "        state = torch.load(ckpt, map_location=DEVICE)\n",
    "        model.load_state_dict(state[\"model_state_dict\"], strict=False)\n",
    "        model.eval()\n",
    "\n",
    "        # Create per-panel subfolders: image_a, image_b, ..., inside this out_dir\n",
    "        panel_ids = ['a', 'b', 'c', 'd', 'e']\n",
    "        panel_dirs = {\n",
    "            pid: out_dir / f\"image_{pid}\"\n",
    "            for pid in panel_ids\n",
    "        }\n",
    "        for d in panel_dirs.values():\n",
    "            d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        random.seed(SEED + ver)\n",
    "        subset = random.sample(imgs, min(PER_CKPT, len(imgs)))\n",
    "        pages = math.ceil(len(subset) / IMGS_PER_FIG)\n",
    "\n",
    "        titles = [\n",
    "            \"Noisy DP\",\n",
    "            \"Sectioned Noisy DP\",\n",
    "            \"Log (Sectioned Noisy DP)\",\n",
    "            \"Denoised DP\",\n",
    "            \"Log (Denoised DP)\",\n",
    "        ]\n",
    "        labels = ['(a)', '(b)', '(c)', '(d)', '(e)']\n",
    "\n",
    "        for page in range(pages):\n",
    "            fig, axs = plt.subplots(\n",
    "                5, IMGS_PER_FIG,\n",
    "                figsize=(IMGS_PER_FIG * 3, 5 * 3),\n",
    "                squeeze=False\n",
    "            )\n",
    "            axs = np.array(axs)\n",
    "\n",
    "            for col in range(IMGS_PER_FIG):\n",
    "                i = page * IMGS_PER_FIG + col\n",
    "                if i >= len(subset):\n",
    "                    break\n",
    "\n",
    "                img_p = subset[i]\n",
    "                no, ring_no, de = denoise_ring(model, img_p)\n",
    "\n",
    "                images = [no, ring_no, to_log(ring_no), de, to_log(de)]\n",
    "\n",
    "                # Save each panel (without rings) in its own folder:\n",
    "                # e.g. \"image_a/name_a.png\", \"image_b/name_b.png\", ...\n",
    "                for arr, pid in zip(images, panel_ids):\n",
    "                    out_name = f\"{img_p.stem}_{pid}.png\"\n",
    "                    out_path = panel_dirs[pid] / out_name\n",
    "                    plt.imsave(out_path, np.clip(arr, 0, 1), cmap=\"gray\")\n",
    "\n",
    "                # Composite figure with rings\n",
    "                for row in range(5):\n",
    "                    ax = axs[row, col]\n",
    "                    arr = images[row]\n",
    "\n",
    "                    ax.imshow(arr, cmap=\"gray\", vmin=0, vmax=1)\n",
    "\n",
    "                    if row in {1, 2, 3, 4}:\n",
    "                        draw_ring(ax, *arr.shape)\n",
    "\n",
    "                    ax.set_title(titles[row], fontsize=16)\n",
    "                    ax.text(\n",
    "                        0.02, 0.95, labels[row],\n",
    "                        transform=ax.transAxes,\n",
    "                        fontsize=12, color='white',\n",
    "                        weight='bold', va='top', ha='left'\n",
    "                    )\n",
    "\n",
    "                    if row == 0:\n",
    "                        ax.text(\n",
    "                            0.98, 0.95, img_p.name, color='white',\n",
    "                            fontsize=12, transform=ax.transAxes,\n",
    "                            ha='right', va='top'\n",
    "                        )\n",
    "\n",
    "                    ax.axis(\"off\")\n",
    "\n",
    "            fig.suptitle(\n",
    "                f\"RDUNet – Experimental Image Denoising (ckpt {ver:02d})\",\n",
    "                fontsize=16\n",
    "            )\n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "            out_png = out_dir / f\"ckpt{ver:02d}_page_{page+1}.png\"\n",
    "            plt.savefig(out_png, dpi=200)\n",
    "            plt.close(fig)\n",
    "            print(\"✓ saved\", out_png)\n",
    "\n",
    "        print(f\"✓ saved composite pages and per-panel images in {out_dir}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee60b6e-c701-4243-9359-43723b181da0",
   "metadata": {},
   "source": [
    "# 4. Phase Idnetification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0168c47b-6a50-485b-a866-6d74a0229eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing (RANSAC hex + O1/O3): 100%|████████| 588/588 [03:19<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/hexagon_outputs/72 denoise 5-20/dp_categories.txt\n",
      "Wrote: /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/hexagon_outputs/72 denoise 5-20/dp_categories.xlsx\n",
      "Wrote: /Users/ethan/Desktop/Materials Simulation MPhil Project/figures/hexagon_outputs/72 denoise 5-20/o1_o3_grid.png\n",
      "Model: {'ok': True, 'reason': 'ok', 'r_o3': 0.94490976464077, 'r_o1': 0.5616582139763803, 'n_train': 106}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Dict, Tuple\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from matplotlib.patches import Patch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, Alignment\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "\n",
    "IMAGE_GLOB = r\"/Users/ethan/Desktop/Materials Simulation MPhil Project/figures/72 denoise 5-20/image_d/*.png\"\n",
    "OUT_ROOT_BASE = \"/Users/ethan/Desktop/Materials Simulation MPhil Project/figures/hexagon_outputs\"\n",
    "\n",
    "CAT_NO_HEX = \"no_hex\"\n",
    "CAT_HEX_NOT_O1O3 = \"yes_hex_but_not_o1_nor_o3\"\n",
    "CAT_O1_ONLY = \"o1_only\"\n",
    "CAT_O3_ONLY = \"o3_only\"\n",
    "CAT_O1_O3 = \"o1_and_o3\"\n",
    "TIMEOUT_CATEGORY = \"skipped_timeout\"\n",
    "\n",
    "WRITE_OVERLAYS = True\n",
    "SHOW_PANEL_TITLES = True\n",
    "SHOW_LEGEND = True\n",
    "\n",
    "# ---- Hard time limits ----\n",
    "MAX_SECONDS_PER_IMAGE = 30.0\n",
    "MAX_SECONDS_MODEL_BUILD = 120.0\n",
    "ENABLE_MODEL_BUILD = True\n",
    "\n",
    "# ---- Normalisation ----\n",
    "NORMALIZE_BY = \"outer\"  # \"outer\" uses r_orange; \"blue\" uses r_blue\n",
    "\n",
    "# ---- Rings by colour ----\n",
    "BLUE_LOWER = np.array([90, 80, 40], dtype=np.uint8)\n",
    "BLUE_UPPER = np.array([140, 255, 255], dtype=np.uint8)\n",
    "ORANGE_LOWER = np.array([10, 80, 40], dtype=np.uint8)\n",
    "ORANGE_UPPER = np.array([25, 255, 255], dtype=np.uint8)\n",
    "\n",
    "FALLBACK_BLUE_FRAC = 0.05\n",
    "FALLBACK_ORANGE_FRAC = 0.20\n",
    "\n",
    "# ---- Annulus / centre masks ----\n",
    "ANN_INNER_MARGIN = 0.90\n",
    "ANN_OUTER_MARGIN = 0.98\n",
    "CENTRE_MAX_FRAC = 0.95\n",
    "\n",
    "# ---- Spot detection (DoG + NMS) ----\n",
    "SPOT_DOWNSAMPLE = 2          # set 1 for maximum sensitivity\n",
    "DOG_SIGMA1 = 1.0\n",
    "DOG_SIGMA2 = 2.2             # > sigma1\n",
    "SPOT_NMS_KSIZE = 9           # local maxima window (odd)\n",
    "SPOT_MIN_REL_ANNULUS = 0.015 # relative to max DoG in annulus\n",
    "SPOT_MIN_REL_CENTRAL = 0.03\n",
    "SPOT_TOPK_ANNULUS_ALL = 300\n",
    "SPOT_TOPK_CENTRAL_ALL = 120\n",
    "SPOT_MIN_SEP_PX = 6.0        # min spacing in original pixels\n",
    "\n",
    "SUBPIX_REFINE = True\n",
    "SUBPIX_WIN = 7               # odd window for centroiding\n",
    "\n",
    "MAX_ANNULUS_SPOTS_FOR_HEX = 90\n",
    "\n",
    "# ---- Hex detection (RANSAC regular hex) ----\n",
    "MAX_HEXAGONS_RETURN = 3\n",
    "MAX_PLOTTED_HEXAGONS = 2\n",
    "\n",
    "HEX_MIN_MATCHED_VERTS = 4\n",
    "HEX_MIN_MATCHED_FOR_TRAIN = 5\n",
    "HEX_MATCH_TOL_FRAC = 0.10        # distance tol = frac * radius\n",
    "HEX_R_TOL_FRAC = 0.10            # ring consistency for sampled points\n",
    "HEX_ANG_TOL_DEG = 10.0\n",
    "HEX_RANSAC_ITERS = 700\n",
    "HEX_JACCARD_MAX = 0.50\n",
    "HEX_SCORE_RMSE_FRAC = 0.06       # rmse must be <= frac * r\n",
    "\n",
    "# ---- Model (learned on NORMALISED radii) ----\n",
    "PHASE_MIN_TRAIN_IMAGES = 10\n",
    "PHASE_TRIM_IQR = 2.0\n",
    "KMEANS_ITERS = 60\n",
    "\n",
    "# True  -> smaller cluster labelled O3\n",
    "# False -> smaller cluster labelled O1 (swap)\n",
    "LABEL_SMALL_AS_O3 = False\n",
    "\n",
    "# USER REQUESTED\n",
    "O1_MATCH_FRAC = 0.15\n",
    "O3_MATCH_FRAC = 0.1\n",
    "\n",
    "# ---- Plot styling ----\n",
    "USED_SPOT_COLOUR = \"magenta\"\n",
    "USED_SPOT_SIZE = 22\n",
    "USED_SPOT_ALPHA = 0.95\n",
    "\n",
    "ALL_SPOT_COLOUR = \"lightgray\"\n",
    "ALL_SPOT_SIZE = 12\n",
    "ALL_SPOT_ALPHA = 0.9\n",
    "\n",
    "CENTRAL_SPOT_COLOUR = \"orange\"\n",
    "CENTRAL_SPOT_MARKER = \"^\"\n",
    "CENTRAL_SPOT_SIZE = 18\n",
    "CENTRAL_SPOT_ALPHA = 0.9\n",
    "\n",
    "PARTIAL_MATCHED_MARKER = \"o\"\n",
    "PARTIAL_MATCHED_FACE = \"white\"\n",
    "PARTIAL_MATCHED_EDGE = \"black\"\n",
    "PARTIAL_MATCHED_SIZE = 55\n",
    "\n",
    "PARTIAL_PRED_MARKER = \"x\"\n",
    "PARTIAL_PRED_COLOUR = \"red\"\n",
    "PARTIAL_PRED_SIZE = 70\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Helpers\n",
    "# ============================================================\n",
    "\n",
    "def get_image_a_path(image_d_path: str) -> str:\n",
    "    d_dir = os.path.dirname(image_d_path)\n",
    "    a_dir = d_dir.replace(os.sep + \"image_d\", os.sep + \"image_a\")\n",
    "\n",
    "    fn = os.path.basename(image_d_path)\n",
    "    stem, ext = os.path.splitext(fn)\n",
    "\n",
    "    if stem.endswith(\"_d\"):\n",
    "        fn_a = stem[:-2] + \"_a\" + ext\n",
    "    elif stem.endswith(\"-d\"):\n",
    "        fn_a = stem[:-2] + \"-a\" + ext\n",
    "    else:\n",
    "        fn_a = fn\n",
    "\n",
    "    return os.path.join(a_dir, fn_a)\n",
    "\n",
    "\n",
    "def _norm_scale(r_blue, r_orange):\n",
    "    if NORMALIZE_BY == \"blue\":\n",
    "        return max(float(r_blue), 1e-9)\n",
    "    return max(float(r_orange), 1e-9)\n",
    "\n",
    "\n",
    "def _resize_mask(mask, new_w, new_h):\n",
    "    return cv2.resize(mask.astype(np.uint8), (new_w, new_h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "\n",
    "def _gaussian(img, sigma):\n",
    "    if sigma <= 0:\n",
    "        return img\n",
    "    k = int(2 * round(3 * sigma) + 1)\n",
    "    return cv2.GaussianBlur(img, (k, k), sigmaX=sigma, sigmaY=sigma)\n",
    "\n",
    "\n",
    "def _find_contours(mask_u8):\n",
    "    res = cv2.findContours(mask_u8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    return res[-2]\n",
    "\n",
    "\n",
    "def _fit_circle_from_mask(mask):\n",
    "    mask = mask.astype(np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8), iterations=1)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((5, 5), np.uint8), iterations=2)\n",
    "    cnts = _find_contours(mask)\n",
    "    if not cnts:\n",
    "        return None\n",
    "    cnt = max(cnts, key=cv2.contourArea)\n",
    "    (x, y), r = cv2.minEnclosingCircle(cnt)\n",
    "    return float(x), float(y), float(r)\n",
    "\n",
    "\n",
    "def detect_ring_centre_and_radii(panel_rgb):\n",
    "    H, W = panel_rgb.shape[:2]\n",
    "    hsv = cv2.cvtColor(panel_rgb, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    mask_blue = cv2.inRange(hsv, BLUE_LOWER, BLUE_UPPER)\n",
    "    mask_orange = cv2.inRange(hsv, ORANGE_LOWER, ORANGE_UPPER)\n",
    "\n",
    "    blue_fit = _fit_circle_from_mask(mask_blue)\n",
    "    orange_fit = _fit_circle_from_mask(mask_orange)\n",
    "\n",
    "    if blue_fit is None or orange_fit is None:\n",
    "        cx, cy = W / 2.0, H / 2.0\n",
    "        r_blue = FALLBACK_BLUE_FRAC * min(H, W)\n",
    "        r_orange = FALLBACK_ORANGE_FRAC * min(H, W)\n",
    "        return (float(cx), float(cy)), float(r_blue), float(r_orange), True\n",
    "\n",
    "    cx = 0.5 * (blue_fit[0] + orange_fit[0])\n",
    "    cy = 0.5 * (blue_fit[1] + orange_fit[1])\n",
    "\n",
    "    ys_b, xs_b = np.where(mask_blue > 0)\n",
    "    ys_o, xs_o = np.where(mask_orange > 0)\n",
    "\n",
    "    r_blue = float(np.median(np.sqrt((xs_b - cx) ** 2 + (ys_b - cy) ** 2))) if len(xs_b) else float(blue_fit[2])\n",
    "    r_orange = float(np.median(np.sqrt((xs_o - cx) ** 2 + (ys_o - cy) ** 2))) if len(xs_o) else float(orange_fit[2])\n",
    "\n",
    "    return (float(cx), float(cy)), r_blue, r_orange, False\n",
    "\n",
    "\n",
    "def make_spot_annulus_mask(shape, centre, r_blue, r_orange,\n",
    "                           inner_margin=ANN_INNER_MARGIN,\n",
    "                           outer_margin=ANN_OUTER_MARGIN):\n",
    "    H, W = shape[:2]\n",
    "    cx, cy = centre\n",
    "    Y, X = np.ogrid[:H, :W]\n",
    "    R = np.sqrt((X - cx) ** 2 + (Y - cy) ** 2)\n",
    "    r_inner = inner_margin * r_blue\n",
    "    r_outer = outer_margin * r_orange\n",
    "    return ((R >= r_inner) & (R <= r_outer)).astype(np.uint8)\n",
    "\n",
    "\n",
    "def pixel_to_cartesian(pts_px, centre_px):\n",
    "    pts_px = np.asarray(pts_px, dtype=float)\n",
    "    if pts_px.size == 0:\n",
    "        return np.empty((0, 2), dtype=float)\n",
    "    cx, cy = centre_px\n",
    "    x = pts_px[:, 0] - cx\n",
    "    y = cy - pts_px[:, 1]\n",
    "    return np.stack([x, y], axis=1)\n",
    "\n",
    "\n",
    "def cartesian_to_pixel(pts_xy, centre_px):\n",
    "    pts_xy = np.asarray(pts_xy, dtype=float)\n",
    "    cx, cy = centre_px\n",
    "    x_px = pts_xy[:, 0] + cx\n",
    "    y_px = cy - pts_xy[:, 1]\n",
    "    return np.stack([x_px, y_px], axis=1)\n",
    "\n",
    "\n",
    "def angle_deg(xy):\n",
    "    a = np.degrees(np.arctan2(xy[..., 1], xy[..., 0]))\n",
    "    return np.mod(a, 360.0)\n",
    "\n",
    "\n",
    "def wrap_angle_deg(a):\n",
    "    return np.mod(a + 180.0, 360.0) - 180.0\n",
    "\n",
    "\n",
    "def iqr_trim(values, k=2.0):\n",
    "    v = np.asarray(values, dtype=float)\n",
    "    v = v[np.isfinite(v)]\n",
    "    if len(v) < 4:\n",
    "        return v\n",
    "    q1, q3 = np.percentile(v, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lo = q1 - k * iqr\n",
    "    hi = q3 + k * iqr\n",
    "    return v[(v >= lo) & (v <= hi)]\n",
    "\n",
    "\n",
    "def kmeans_1d_two_clusters(x, iters=60):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    x = x[np.isfinite(x)]\n",
    "    if len(x) < 2:\n",
    "        return None\n",
    "\n",
    "    c0, c1 = np.percentile(x, [30, 70])\n",
    "    if np.isclose(c0, c1):\n",
    "        return None\n",
    "\n",
    "    for _ in range(iters):\n",
    "        d0 = np.abs(x - c0)\n",
    "        d1 = np.abs(x - c1)\n",
    "        m0 = d0 <= d1\n",
    "        m1 = ~m0\n",
    "        if m0.sum() == 0 or m1.sum() == 0:\n",
    "            break\n",
    "        nc0 = x[m0].mean()\n",
    "        nc1 = x[m1].mean()\n",
    "        if np.isclose(nc0, c0) and np.isclose(nc1, c1):\n",
    "            break\n",
    "        c0, c1 = nc0, nc1\n",
    "\n",
    "    return tuple(sorted([float(c0), float(c1)]))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Spot detection: DoG + NMS + optional subpixel centroid\n",
    "# ============================================================\n",
    "\n",
    "def _nms_peaks(score_img, mask_u8, ksize, min_rel, topk):\n",
    "    masked = score_img.copy()\n",
    "    masked[mask_u8 == 0] = 0.0\n",
    "    vmax = float(masked.max())\n",
    "    if vmax <= 1e-9:\n",
    "        return np.empty((0, 2), dtype=float), np.empty((0,), dtype=float)\n",
    "\n",
    "    thr = min_rel * vmax\n",
    "\n",
    "    k = max(3, int(ksize) | 1)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (k, k))\n",
    "    dil = cv2.dilate(masked, kernel)\n",
    "\n",
    "    is_peak = (masked >= dil - 1e-12) & (masked >= thr) & (mask_u8 > 0)\n",
    "    ys, xs = np.where(is_peak)\n",
    "    if len(xs) == 0:\n",
    "        return np.empty((0, 2), dtype=float), np.empty((0,), dtype=float)\n",
    "\n",
    "    vals = masked[ys, xs]\n",
    "    order = np.argsort(vals)[::-1]\n",
    "    if topk is not None and len(order) > topk:\n",
    "        order = order[:topk]\n",
    "\n",
    "    xs = xs[order].astype(float)\n",
    "    ys = ys[order].astype(float)\n",
    "    vals = vals[order].astype(float)\n",
    "\n",
    "    pts = np.stack([xs, ys], axis=1)\n",
    "    return pts, vals\n",
    "\n",
    "\n",
    "def _min_sep_filter(points, scores, min_sep):\n",
    "    if len(points) == 0:\n",
    "        return points, scores\n",
    "    pts = np.asarray(points, dtype=float)\n",
    "    sc = np.asarray(scores, dtype=float)\n",
    "    order = np.argsort(sc)[::-1]\n",
    "    pts = pts[order]\n",
    "    sc = sc[order]\n",
    "\n",
    "    kept_pts = []\n",
    "    kept_sc = []\n",
    "    for p, s in zip(pts, sc):\n",
    "        ok = True\n",
    "        for q in kept_pts:\n",
    "            if np.linalg.norm(p - q) <= min_sep:\n",
    "                ok = False\n",
    "                break\n",
    "        if ok:\n",
    "            kept_pts.append(p)\n",
    "            kept_sc.append(s)\n",
    "\n",
    "    return np.asarray(kept_pts, dtype=float), np.asarray(kept_sc, dtype=float)\n",
    "\n",
    "\n",
    "def _subpixel_centroid(gray_norm, pts_xy, win=7):\n",
    "    H, W = gray_norm.shape\n",
    "    r = int(win // 2)\n",
    "    out = []\n",
    "    for x, y in pts_xy:\n",
    "        xi = int(round(x))\n",
    "        yi = int(round(y))\n",
    "        x0 = max(0, xi - r)\n",
    "        x1 = min(W, xi + r + 1)\n",
    "        y0 = max(0, yi - r)\n",
    "        y1 = min(H, yi + r + 1)\n",
    "        patch = gray_norm[y0:y1, x0:x1]\n",
    "        if patch.size == 0:\n",
    "            out.append([x, y])\n",
    "            continue\n",
    "        yy, xx = np.mgrid[y0:y1, x0:x1]\n",
    "        w = patch.astype(float)\n",
    "        wsum = float(w.sum())\n",
    "        if wsum <= 1e-9:\n",
    "            out.append([x, y])\n",
    "            continue\n",
    "        cx = float((xx * w).sum() / wsum)\n",
    "        cy = float((yy * w).sum() / wsum)\n",
    "        out.append([cx, cy])\n",
    "    return np.asarray(out, dtype=float)\n",
    "\n",
    "\n",
    "def detect_spots(panel_rgb, centre_px, r_blue, r_orange):\n",
    "    gray = cv2.cvtColor(panel_rgb, cv2.COLOR_RGB2GRAY).astype(np.float32)\n",
    "    gray_norm = (gray - gray.min()) / (gray.max() - gray.min() + 1e-9)\n",
    "\n",
    "    H, W = gray_norm.shape\n",
    "    ds = max(1, int(SPOT_DOWNSAMPLE))\n",
    "\n",
    "    if ds > 1:\n",
    "        new_w = max(16, W // ds)\n",
    "        new_h = max(16, H // ds)\n",
    "        g_ds = cv2.resize(gray_norm, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "    else:\n",
    "        new_h, new_w = H, W\n",
    "        g_ds = gray_norm.copy()\n",
    "\n",
    "    g1 = _gaussian(g_ds, DOG_SIGMA1)\n",
    "    g2 = _gaussian(g_ds, DOG_SIGMA2)\n",
    "    dog = (g1 - g2).astype(np.float32)\n",
    "    dog = np.clip(dog, 0.0, None)\n",
    "\n",
    "    ann_mask = make_spot_annulus_mask((H, W), centre_px, r_blue, r_orange,\n",
    "                                      inner_margin=ANN_INNER_MARGIN,\n",
    "                                      outer_margin=ANN_OUTER_MARGIN)\n",
    "    ann_mask_ds = _resize_mask(ann_mask, new_w, new_h)\n",
    "\n",
    "    cx, cy = centre_px\n",
    "    Y, X = np.ogrid[:H, :W]\n",
    "    R = np.sqrt((X - cx) ** 2 + (Y - cy) ** 2)\n",
    "    cen_mask = (R <= CENTRE_MAX_FRAC * r_blue).astype(np.uint8)\n",
    "    cen_mask_ds = _resize_mask(cen_mask, new_w, new_h)\n",
    "\n",
    "    ann_pts_ds, ann_sc = _nms_peaks(dog, ann_mask_ds, SPOT_NMS_KSIZE, SPOT_MIN_REL_ANNULUS, SPOT_TOPK_ANNULUS_ALL)\n",
    "    cen_pts_ds, cen_sc = _nms_peaks(dog, cen_mask_ds, SPOT_NMS_KSIZE, SPOT_MIN_REL_CENTRAL, SPOT_TOPK_CENTRAL_ALL)\n",
    "\n",
    "    if ds > 1:\n",
    "        ann_pts = ann_pts_ds * ds\n",
    "        cen_pts = cen_pts_ds * ds\n",
    "    else:\n",
    "        ann_pts = ann_pts_ds\n",
    "        cen_pts = cen_pts_ds\n",
    "\n",
    "    ann_pts, ann_sc = _min_sep_filter(ann_pts, ann_sc, SPOT_MIN_SEP_PX)\n",
    "    cen_pts, cen_sc = _min_sep_filter(cen_pts, cen_sc, SPOT_MIN_SEP_PX)\n",
    "\n",
    "    if SUBPIX_REFINE and len(ann_pts):\n",
    "        ann_pts = _subpixel_centroid(gray_norm, ann_pts, win=SUBPIX_WIN)\n",
    "    if SUBPIX_REFINE and len(cen_pts):\n",
    "        cen_pts = _subpixel_centroid(gray_norm, cen_pts, win=SUBPIX_WIN)\n",
    "\n",
    "    if len(ann_pts) > MAX_ANNULUS_SPOTS_FOR_HEX:\n",
    "        xs = np.clip(np.round(ann_pts[:, 0]).astype(int), 0, W - 1)\n",
    "        ys = np.clip(np.round(ann_pts[:, 1]).astype(int), 0, H - 1)\n",
    "        xs_ds = np.clip((xs / ds).astype(int), 0, new_w - 1)\n",
    "        ys_ds = np.clip((ys / ds).astype(int), 0, new_h - 1)\n",
    "        vals = dog[ys_ds, xs_ds]\n",
    "        keep = np.argsort(vals)[::-1][:MAX_ANNULUS_SPOTS_FOR_HEX]\n",
    "        ann_for_hex = ann_pts[keep]\n",
    "    else:\n",
    "        ann_for_hex = ann_pts.copy()\n",
    "\n",
    "    return ann_pts, ann_for_hex, cen_pts, gray_norm\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Hex detection: RANSAC fit of regular hexagon on a ring\n",
    "# ============================================================\n",
    "\n",
    "@dataclass\n",
    "class HexCandidate:\n",
    "    r_px: float\n",
    "    r_norm: float\n",
    "    phi_deg: float\n",
    "    pred_vertices_px: np.ndarray\n",
    "    match_indices: List[Optional[int]]\n",
    "    matched_count: int\n",
    "    rmse: float\n",
    "\n",
    "    @property\n",
    "    def kind(self):\n",
    "        return \"full\" if self.matched_count == 6 else \"partial\"\n",
    "\n",
    "\n",
    "def _predict_hex_vertices(centre_px, r_px, phi_deg):\n",
    "    phi = float(phi_deg)\n",
    "    angs = np.deg2rad((phi + np.arange(6) * 60.0) % 360.0)\n",
    "    xy = np.stack([r_px * np.cos(angs), r_px * np.sin(angs)], axis=1)\n",
    "    return cartesian_to_pixel(xy, centre_px)\n",
    "\n",
    "\n",
    "def _match_vertices_to_points(pred_px, points_px, tol_px):\n",
    "    pts = np.asarray(points_px, dtype=float)\n",
    "    used = set()\n",
    "    match_idx = []\n",
    "    dists_used = []\n",
    "\n",
    "    for v in pred_px:\n",
    "        if len(pts) == 0:\n",
    "            match_idx.append(None)\n",
    "            continue\n",
    "        d = np.linalg.norm(pts - v[None, :], axis=1)\n",
    "        j = int(np.argmin(d))\n",
    "        if float(d[j]) <= tol_px and j not in used:\n",
    "            used.add(j)\n",
    "            match_idx.append(j)\n",
    "            dists_used.append(float(d[j]))\n",
    "        else:\n",
    "            match_idx.append(None)\n",
    "\n",
    "    rmse = float(np.sqrt(np.mean(np.square(dists_used)))) if dists_used else 1e9\n",
    "    matched = sum(m is not None for m in match_idx)\n",
    "    return match_idx, rmse, matched\n",
    "\n",
    "\n",
    "def _jaccard(a_idx, b_idx):\n",
    "    a = {i for i in a_idx if i is not None}\n",
    "    b = {i for i in b_idx if i is not None}\n",
    "    if not a and not b:\n",
    "        return 0.0\n",
    "    inter = len(a & b)\n",
    "    uni = len(a | b)\n",
    "    return inter / uni if uni else 0.0\n",
    "\n",
    "\n",
    "def find_hexagons_ransac(points_px, centre_px, scale_px, deadline=None) -> List[HexCandidate]:\n",
    "    pts = np.asarray(points_px, dtype=float)\n",
    "    if len(pts) < 4:\n",
    "        return []\n",
    "\n",
    "    cart = pixel_to_cartesian(pts, centre_px)\n",
    "    rs = np.linalg.norm(cart, axis=1)\n",
    "    thetas = angle_deg(cart)\n",
    "\n",
    "    rng = np.random.default_rng(0)\n",
    "\n",
    "    best: List[HexCandidate] = []\n",
    "\n",
    "    def try_add(cand: HexCandidate):\n",
    "        for existing in best:\n",
    "            if _jaccard(existing.match_indices, cand.match_indices) > HEX_JACCARD_MAX:\n",
    "                return\n",
    "        best.append(cand)\n",
    "\n",
    "    n = len(pts)\n",
    "    for _ in range(HEX_RANSAC_ITERS):\n",
    "        if deadline is not None and time.monotonic() > deadline:\n",
    "            break\n",
    "\n",
    "        i, j = rng.integers(0, n, size=2)\n",
    "        if i == j:\n",
    "            continue\n",
    "\n",
    "        ri, rj = float(rs[i]), float(rs[j])\n",
    "        if ri <= 1e-6 or rj <= 1e-6:\n",
    "            continue\n",
    "\n",
    "        r0 = 0.5 * (ri + rj)\n",
    "\n",
    "        if abs(ri - rj) > HEX_R_TOL_FRAC * r0:\n",
    "            continue\n",
    "\n",
    "        ti, tj = float(thetas[i]), float(thetas[j])\n",
    "        dtheta = wrap_angle_deg(tj - ti)\n",
    "\n",
    "        ok = False\n",
    "        for k in range(1, 6):\n",
    "            target = k * 60.0\n",
    "            if abs(abs(dtheta) - target) <= HEX_ANG_TOL_DEG:\n",
    "                ok = True\n",
    "                break\n",
    "        if not ok:\n",
    "            continue\n",
    "\n",
    "        best_local = None\n",
    "        for m in range(6):\n",
    "            phi = (ti - m * 60.0) % 360.0\n",
    "            pred = _predict_hex_vertices(centre_px, r0, phi)\n",
    "            tol_px = HEX_MATCH_TOL_FRAC * r0\n",
    "            match_idx, rmse, matched = _match_vertices_to_points(pred, pts, tol_px)\n",
    "\n",
    "            if matched < HEX_MIN_MATCHED_VERTS:\n",
    "                continue\n",
    "            if rmse > HEX_SCORE_RMSE_FRAC * r0:\n",
    "                continue\n",
    "\n",
    "            key = (matched, -rmse)\n",
    "            if best_local is None or key > best_local[0]:\n",
    "                best_local = (key, phi, pred, match_idx, rmse, matched)\n",
    "\n",
    "        if best_local is None:\n",
    "            continue\n",
    "\n",
    "        _, phi, _, match_idx, _, _ = best_local\n",
    "\n",
    "        used = [idx for idx in match_idx if idx is not None]\n",
    "        r_ref = float(np.median(rs[used])) if len(used) >= 3 else r0\n",
    "\n",
    "        pred2 = _predict_hex_vertices(centre_px, r_ref, phi)\n",
    "        tol2 = HEX_MATCH_TOL_FRAC * r_ref\n",
    "        match_idx2, rmse2, matched2 = _match_vertices_to_points(pred2, pts, tol2)\n",
    "        if matched2 < HEX_MIN_MATCHED_VERTS or rmse2 > HEX_SCORE_RMSE_FRAC * r_ref:\n",
    "            continue\n",
    "\n",
    "        cand = HexCandidate(\n",
    "            r_px=r_ref,\n",
    "            r_norm=float(r_ref / max(scale_px, 1e-9)),\n",
    "            phi_deg=float(phi),\n",
    "            pred_vertices_px=pred2,\n",
    "            match_indices=[(int(x) if x is not None else None) for x in match_idx2],\n",
    "            matched_count=int(matched2),\n",
    "            rmse=float(rmse2),\n",
    "        )\n",
    "        try_add(cand)\n",
    "\n",
    "        best.sort(key=lambda c: (-c.matched_count, c.rmse))\n",
    "        best = best[:MAX_HEXAGONS_RETURN]\n",
    "\n",
    "    best.sort(key=lambda c: (-c.matched_count, c.rmse))\n",
    "    return best\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Model build + classification\n",
    "# ============================================================\n",
    "\n",
    "def build_o3_o1_model(paths):\n",
    "    if not ENABLE_MODEL_BUILD:\n",
    "        return {\"ok\": False, \"reason\": \"model_build_disabled\", \"r_o3\": None, \"r_o1\": None, \"n_train\": 0}\n",
    "\n",
    "    t0 = time.monotonic()\n",
    "    used_images = 0\n",
    "    all_r_norm = []\n",
    "\n",
    "    for path in tqdm(paths, desc=\"Learning O3/O1 (RANSAC)\", leave=False):\n",
    "        if time.monotonic() - t0 > MAX_SECONDS_MODEL_BUILD:\n",
    "            return {\"ok\": False, \"reason\": \"model_build_time_budget_exceeded\", \"r_o3\": None, \"r_o1\": None, \"n_train\": used_images}\n",
    "\n",
    "        img_bgr = cv2.imread(path)\n",
    "        if img_bgr is None:\n",
    "            continue\n",
    "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        centre_px, r_blue, r_orange, _ = detect_ring_centre_and_radii(img_rgb)\n",
    "        scale = _norm_scale(r_blue, r_orange)\n",
    "\n",
    "        _, ann_for_hex, _, _ = detect_spots(img_rgb, centre_px, r_blue, r_orange)\n",
    "\n",
    "        deadline = time.monotonic() + MAX_SECONDS_PER_IMAGE\n",
    "        cands = find_hexagons_ransac(ann_for_hex, centre_px, scale, deadline=deadline)\n",
    "\n",
    "        strong = [c for c in cands if c.matched_count >= HEX_MIN_MATCHED_FOR_TRAIN]\n",
    "        if not strong:\n",
    "            continue\n",
    "\n",
    "        strong.sort(key=lambda c: (-c.matched_count, c.rmse))\n",
    "        top = strong[:2]\n",
    "        for c in top:\n",
    "            all_r_norm.append(float(c.r_norm))\n",
    "        used_images += 1\n",
    "\n",
    "    if used_images < PHASE_MIN_TRAIN_IMAGES or len(all_r_norm) < 10:\n",
    "        return {\"ok\": False, \"reason\": \"not_enough_training_images\", \"r_o3\": None, \"r_o1\": None, \"n_train\": used_images}\n",
    "\n",
    "    all_r_t = iqr_trim(all_r_norm, k=PHASE_TRIM_IQR)\n",
    "    if len(all_r_t) < 10:\n",
    "        all_r_t = np.asarray(all_r_norm, dtype=float)\n",
    "\n",
    "    km = kmeans_1d_two_clusters(all_r_t, iters=KMEANS_ITERS)\n",
    "    if km is None:\n",
    "        return {\"ok\": False, \"reason\": \"kmeans_failed\", \"r_o3\": None, \"r_o1\": None, \"n_train\": used_images}\n",
    "\n",
    "    r_small_ref, r_large_ref = km\n",
    "    if LABEL_SMALL_AS_O3:\n",
    "        r_o3, r_o1 = r_small_ref, r_large_ref\n",
    "    else:\n",
    "        r_o3, r_o1 = r_large_ref, r_small_ref\n",
    "\n",
    "    return {\"ok\": True, \"reason\": \"ok\", \"r_o3\": float(r_o3), \"r_o1\": float(r_o1), \"n_train\": used_images}\n",
    "\n",
    "\n",
    "def classify_category(radii_norm, model):\n",
    "    if radii_norm is None or len(radii_norm) == 0:\n",
    "        return CAT_NO_HEX, False, False\n",
    "\n",
    "    if model is None or (not model.get(\"ok\", False)):\n",
    "        return CAT_HEX_NOT_O1O3, False, False\n",
    "\n",
    "    r_o3 = float(model[\"r_o3\"])\n",
    "    r_o1 = float(model[\"r_o1\"])\n",
    "    rs = np.asarray(radii_norm, dtype=float)\n",
    "\n",
    "    tol_o3 = O3_MATCH_FRAC * r_o3\n",
    "    tol_o1 = O1_MATCH_FRAC * r_o1\n",
    "\n",
    "    has_o3 = False\n",
    "    has_o1 = False\n",
    "\n",
    "    for r in rs:\n",
    "        d3 = abs(r - r_o3)\n",
    "        d1 = abs(r - r_o1)\n",
    "        m3 = d3 <= tol_o3\n",
    "        m1 = d1 <= tol_o1\n",
    "\n",
    "        if m3 and m1:\n",
    "            # ambiguous: assign to closer only\n",
    "            if d3 <= d1:\n",
    "                has_o3 = True\n",
    "            else:\n",
    "                has_o1 = True\n",
    "        elif m3:\n",
    "            has_o3 = True\n",
    "        elif m1:\n",
    "            has_o1 = True\n",
    "\n",
    "    if has_o1 and has_o3:\n",
    "        return CAT_O1_O3, True, True\n",
    "    if has_o1:\n",
    "        return CAT_O1_ONLY, True, False\n",
    "    if has_o3:\n",
    "        return CAT_O3_ONLY, False, True\n",
    "    return CAT_HEX_NOT_O1O3, False, False\n",
    "\n",
    "\n",
    "def explain_reason(category, model, radii_norm_all, fallback_used):\n",
    "    if category == TIMEOUT_CATEGORY:\n",
    "        return \"Skipped: timeout during hex detection.\"\n",
    "    if category == CAT_NO_HEX:\n",
    "        return \"No hex lattice detected in annulus (RANSAC).\"\n",
    "\n",
    "    if model is None or (not model.get(\"ok\", False)):\n",
    "        why = \"unknown\" if model is None else model.get(\"reason\", \"unknown\")\n",
    "        return f\"Model unavailable, so cannot label O1/O3 (model_reason={why}).\"\n",
    "\n",
    "    r_o1 = float(model[\"r_o1\"])\n",
    "    r_o3 = float(model[\"r_o3\"])\n",
    "    tol_o1 = O1_MATCH_FRAC * r_o1\n",
    "    tol_o3 = O3_MATCH_FRAC * r_o3\n",
    "\n",
    "    rs = np.asarray(radii_norm_all, dtype=float)\n",
    "    fb = \" Ring radii used fallback.\" if fallback_used else \"\"\n",
    "\n",
    "    if category == CAT_O1_O3:\n",
    "        return f\"Matched both O1 (±{O1_MATCH_FRAC:.0%}) and O3 (±{O3_MATCH_FRAC:.0%}).{fb}\"\n",
    "    if category == CAT_O1_ONLY:\n",
    "        return f\"Matched O1 (±{O1_MATCH_FRAC:.0%}) but no O3 match.{fb}\"\n",
    "    if category == CAT_O3_ONLY:\n",
    "        return f\"Matched O3 (±{O3_MATCH_FRAC:.0%}) but no O1 match.{fb}\"\n",
    "\n",
    "    rs_str = \",\".join(f\"{x:.4f}\" for x in rs.tolist()[:8])\n",
    "    if len(rs) > 8:\n",
    "        rs_str += \",...\"\n",
    "    return (f\"Detected radii(norm) [{rs_str}] do not match \"\n",
    "            f\"O1={r_o1:.4f}±{tol_o1:.4f} nor O3={r_o3:.4f}±{tol_o3:.4f}.{fb}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Plot helpers\n",
    "# ============================================================\n",
    "\n",
    "def build_overlay_legend_handles(show_other=True):\n",
    "    handles = [\n",
    "        Line2D([0], [0], color=\"cyan\", lw=2.2, label=\"O3 hex (radius match)\"),\n",
    "        Line2D([0], [0], color=\"yellow\", lw=2.2, label=\"O1 hex (radius match)\"),\n",
    "    ]\n",
    "    if show_other:\n",
    "        handles.append(Line2D([0], [0], color=\"lime\", lw=2.2, label=\"Other hex (no match)\"))\n",
    "\n",
    "    handles += [\n",
    "        Line2D([0], [0], color=\"blue\", lw=1.6, label=\"Inner ring\"),\n",
    "        Line2D([0], [0], color=\"orange\", lw=1.6, label=\"Outer ring\"),\n",
    "        Line2D([0], [0], marker=\"o\", linestyle=\"None\",\n",
    "               markerfacecolor=USED_SPOT_COLOUR, markeredgecolor=USED_SPOT_COLOUR,\n",
    "               markersize=6, label=\"Used vertices (matched)\"),\n",
    "        Line2D([0], [0], marker=PARTIAL_MATCHED_MARKER, linestyle=\"None\",\n",
    "               markerfacecolor=PARTIAL_MATCHED_FACE, markeredgecolor=PARTIAL_MATCHED_EDGE,\n",
    "               markersize=7, label=\"Partial: matched vertices\"),\n",
    "        Line2D([0], [0], marker=PARTIAL_PRED_MARKER, linestyle=\"None\",\n",
    "               color=PARTIAL_PRED_COLOUR, markersize=7, label=\"Partial: predicted missing\"),\n",
    "    ]\n",
    "    return handles\n",
    "\n",
    "\n",
    "def build_points_legend_handles():\n",
    "    return [\n",
    "        Line2D([0], [0], color=\"blue\", lw=1.6, label=\"Inner ring\"),\n",
    "        Line2D([0], [0], color=\"orange\", lw=1.6, label=\"Outer ring\"),\n",
    "        Line2D([0], [0], marker=\"o\", linestyle=\"None\",\n",
    "               markerfacecolor=\"lightgray\", markeredgecolor=\"lightgray\",\n",
    "               markersize=6, label=\"All annulus spots (detected)\"),\n",
    "        Line2D([0], [0], marker=CENTRAL_SPOT_MARKER, linestyle=\"None\",\n",
    "               color=CENTRAL_SPOT_COLOUR, markersize=7, label=\"All central spots (detected)\"),\n",
    "        Line2D([0], [0], marker=PARTIAL_PRED_MARKER, linestyle=\"None\",\n",
    "               color=PARTIAL_PRED_COLOUR, markersize=7, label=\"Predicted missing (partial)\"),\n",
    "    ]\n",
    "\n",
    "\n",
    "def colour_for_radius_norm(r_norm, model):\n",
    "    if model is None or (not model.get(\"ok\", False)):\n",
    "        return \"lime\"\n",
    "    r_o3 = float(model[\"r_o3\"])\n",
    "    r_o1 = float(model[\"r_o1\"])\n",
    "\n",
    "    # if ambiguous, colour by closer\n",
    "    d3 = abs(r_norm - r_o3)\n",
    "    d1 = abs(r_norm - r_o1)\n",
    "    m3 = d3 <= O3_MATCH_FRAC * r_o3\n",
    "    m1 = d1 <= O1_MATCH_FRAC * r_o1\n",
    "\n",
    "    if m3 and m1:\n",
    "        return \"cyan\" if d3 <= d1 else \"yellow\"\n",
    "    if m3:\n",
    "        return \"cyan\"\n",
    "    if m1:\n",
    "        return \"yellow\"\n",
    "    return \"lime\"\n",
    "\n",
    "\n",
    "def pick_lattices_to_plot(cands: List[\"HexCandidate\"], model):\n",
    "    if not cands:\n",
    "        return [], False\n",
    "\n",
    "    model_ok = bool(model and model.get(\"ok\", False))\n",
    "    if model_ok:\n",
    "        r_o1 = float(model[\"r_o1\"])\n",
    "        r_o3 = float(model[\"r_o3\"])\n",
    "        tol_o1 = O1_MATCH_FRAC * r_o1\n",
    "        tol_o3 = O3_MATCH_FRAC * r_o3\n",
    "\n",
    "        o1 = [c for c in cands if abs(c.r_norm - r_o1) <= tol_o1]\n",
    "        o3 = [c for c in cands if abs(c.r_norm - r_o3) <= tol_o3]\n",
    "\n",
    "        def best_of(lst):\n",
    "            if not lst:\n",
    "                return None\n",
    "            lst = sorted(lst, key=lambda c: (-c.matched_count, c.rmse))\n",
    "            return lst[0]\n",
    "\n",
    "        b1 = best_of(o1)\n",
    "        b3 = best_of(o3)\n",
    "\n",
    "        chosen = []\n",
    "        if b1 is not None:\n",
    "            chosen.append(b1)\n",
    "        if b3 is not None and (b3 is not b1):\n",
    "            chosen.append(b3)\n",
    "\n",
    "        if chosen:\n",
    "            return chosen[:MAX_PLOTTED_HEXAGONS], True\n",
    "\n",
    "    cands = sorted(cands, key=lambda c: (-c.matched_count, c.rmse))\n",
    "    return cands[:MAX_PLOTTED_HEXAGONS], False\n",
    "\n",
    "\n",
    "def unique_points(points_px, tol_px=0.75):\n",
    "    pts = np.asarray(points_px, dtype=float)\n",
    "    if pts.size == 0:\n",
    "        return pts\n",
    "    kept = []\n",
    "    for p in pts:\n",
    "        ok = True\n",
    "        for q in kept:\n",
    "            if np.linalg.norm(p - q) <= tol_px:\n",
    "                ok = False\n",
    "                break\n",
    "        if ok:\n",
    "            kept.append(p)\n",
    "    return np.asarray(kept, dtype=float)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Analyse one image + overlay\n",
    "# ============================================================\n",
    "\n",
    "def analyse_one(img_d_rgb, image_d_path, out_root, model):\n",
    "    img_a_rgb = None\n",
    "    image_a_path = get_image_a_path(image_d_path)\n",
    "    if os.path.exists(image_a_path):\n",
    "        a_bgr = cv2.imread(image_a_path)\n",
    "        if a_bgr is not None:\n",
    "            img_a_rgb = cv2.cvtColor(a_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    centre_px, r_blue, r_orange, used_fallback = detect_ring_centre_and_radii(img_d_rgb)\n",
    "    scale = _norm_scale(r_blue, r_orange)\n",
    "\n",
    "    ann_all, ann_for_hex, cen_all, _ = detect_spots(img_d_rgb, centre_px, r_blue, r_orange)\n",
    "\n",
    "    deadline = time.monotonic() + MAX_SECONDS_PER_IMAGE\n",
    "    cands = find_hexagons_ransac(ann_for_hex, centre_px, scale, deadline=deadline)\n",
    "\n",
    "    radii_norm_all = [float(c.r_norm) for c in cands]\n",
    "    radii_px_all = [float(c.r_px) for c in cands]\n",
    "\n",
    "    if len(cands) == 0:\n",
    "        category = CAT_NO_HEX\n",
    "    else:\n",
    "        category, _, _ = classify_category(radii_norm_all, model)\n",
    "\n",
    "    reason = explain_reason(category, model, radii_norm_all, used_fallback)\n",
    "\n",
    "    out_dir = os.path.join(out_root, category)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    plot_list, suppress_other = pick_lattices_to_plot(cands, model)\n",
    "    radii_norm_plotted = [float(c.r_norm) for c in plot_list]\n",
    "    radii_px_plotted = [float(c.r_px) for c in plot_list]\n",
    "\n",
    "    used_measured_pts = []\n",
    "    used_predicted_pts = []\n",
    "\n",
    "    for c in plot_list:\n",
    "        col = colour_for_radius_norm(c.r_norm, model)\n",
    "        if suppress_other and col == \"lime\":\n",
    "            continue\n",
    "\n",
    "        pred = c.pred_vertices_px\n",
    "        for v_idx, m in enumerate(c.match_indices):\n",
    "            if m is not None:\n",
    "                used_measured_pts.append(ann_for_hex[m])\n",
    "            else:\n",
    "                used_predicted_pts.append(pred[v_idx])\n",
    "\n",
    "    used_measured_pts = unique_points(np.array(used_measured_pts, dtype=float) if len(used_measured_pts) else np.empty((0, 2)))\n",
    "    used_predicted_pts = unique_points(np.array(used_predicted_pts, dtype=float) if len(used_predicted_pts) else np.empty((0, 2)))\n",
    "\n",
    "    if WRITE_OVERLAYS:\n",
    "        if img_a_rgb is not None:\n",
    "            fig = plt.figure(figsize=(18, 4))\n",
    "            gs = fig.add_gridspec(1, 5, width_ratios=[1, 1, 1, 1, 0.72])\n",
    "            ax_a = fig.add_subplot(gs[0, 0])\n",
    "            ax_d = fig.add_subplot(gs[0, 1])\n",
    "            ax_ov = fig.add_subplot(gs[0, 2])\n",
    "            ax_pts = fig.add_subplot(gs[0, 3])\n",
    "            ax_leg = fig.add_subplot(gs[0, 4])\n",
    "\n",
    "            ax_a.imshow(img_a_rgb)\n",
    "            ax_a.axis(\"off\")\n",
    "            if SHOW_PANEL_TITLES:\n",
    "                ax_a.set_title(\"Original denoised (A)\")\n",
    "        else:\n",
    "            fig = plt.figure(figsize=(14, 4))\n",
    "            gs = fig.add_gridspec(1, 4, width_ratios=[1, 1, 1, 0.72])\n",
    "            ax_d = fig.add_subplot(gs[0, 0])\n",
    "            ax_ov = fig.add_subplot(gs[0, 1])\n",
    "            ax_pts = fig.add_subplot(gs[0, 2])\n",
    "            ax_leg = fig.add_subplot(gs[0, 3])\n",
    "\n",
    "        ax_d.imshow(img_d_rgb)\n",
    "        ax_d.axis(\"off\")\n",
    "        if SHOW_PANEL_TITLES:\n",
    "            ax_d.set_title(\"Log denoised (D)\")\n",
    "\n",
    "        ax_ov.imshow(img_d_rgb)\n",
    "        ax_ov.axis(\"off\")\n",
    "        if SHOW_PANEL_TITLES:\n",
    "            ax_ov.set_title(\"Hexagons found (RANSAC)\")\n",
    "\n",
    "        ax_ov.add_patch(Circle(centre_px, r_blue, fill=False, edgecolor=\"blue\", linewidth=1))\n",
    "        ax_ov.add_patch(Circle(centre_px, r_orange, fill=False, edgecolor=\"orange\", linewidth=1))\n",
    "\n",
    "        if len(used_measured_pts):\n",
    "            ax_ov.scatter(used_measured_pts[:, 0], used_measured_pts[:, 1],\n",
    "                          s=USED_SPOT_SIZE, c=USED_SPOT_COLOUR,\n",
    "                          alpha=USED_SPOT_ALPHA, zorder=3)\n",
    "\n",
    "        for c in plot_list:\n",
    "            col = colour_for_radius_norm(c.r_norm, model)\n",
    "            if suppress_other and col == \"lime\":\n",
    "                continue\n",
    "\n",
    "            pred = c.pred_vertices_px\n",
    "            ax_ov.plot(np.r_[pred[:, 0], pred[0, 0]],\n",
    "                       np.r_[pred[:, 1], pred[0, 1]],\n",
    "                       c=col, linewidth=2.2, alpha=0.95, zorder=6)\n",
    "\n",
    "            measured = []\n",
    "            missing = []\n",
    "            for v_idx, m in enumerate(c.match_indices):\n",
    "                if m is not None:\n",
    "                    measured.append(ann_for_hex[m])\n",
    "                else:\n",
    "                    missing.append(pred[v_idx])\n",
    "\n",
    "            if measured:\n",
    "                measured = np.array(measured, dtype=float)\n",
    "                ax_ov.scatter(measured[:, 0], measured[:, 1],\n",
    "                              s=PARTIAL_MATCHED_SIZE, marker=PARTIAL_MATCHED_MARKER,\n",
    "                              c=PARTIAL_MATCHED_FACE, edgecolors=PARTIAL_MATCHED_EDGE,\n",
    "                              linewidths=0.8, zorder=8)\n",
    "\n",
    "            if missing:\n",
    "                missing = np.array(missing, dtype=float)\n",
    "                ax_ov.scatter(missing[:, 0], missing[:, 1],\n",
    "                              s=PARTIAL_PRED_SIZE, marker=PARTIAL_PRED_MARKER,\n",
    "                              c=PARTIAL_PRED_COLOUR, linewidths=1.3, zorder=9)\n",
    "\n",
    "        ax_pts.axis(\"off\")\n",
    "        if SHOW_PANEL_TITLES:\n",
    "            ax_pts.set_title(\"All detected spots (black canvas)\")\n",
    "\n",
    "        H, W = img_d_rgb.shape[:2]\n",
    "        black = np.zeros((H, W, 3), dtype=np.uint8)\n",
    "        ax_pts.imshow(black)\n",
    "        ax_pts.set_xlim(0, W)\n",
    "        ax_pts.set_ylim(H, 0)\n",
    "\n",
    "        ax_pts.add_patch(Circle(centre_px, r_blue, fill=False, edgecolor=\"blue\", linewidth=1))\n",
    "        ax_pts.add_patch(Circle(centre_px, r_orange, fill=False, edgecolor=\"orange\", linewidth=1))\n",
    "\n",
    "        if len(ann_all):\n",
    "            ax_pts.scatter(ann_all[:, 0], ann_all[:, 1],\n",
    "                           s=ALL_SPOT_SIZE, c=ALL_SPOT_COLOUR,\n",
    "                           alpha=ALL_SPOT_ALPHA, zorder=3)\n",
    "        if len(cen_all):\n",
    "            ax_pts.scatter(cen_all[:, 0], cen_all[:, 1],\n",
    "                           s=CENTRAL_SPOT_SIZE, marker=CENTRAL_SPOT_MARKER,\n",
    "                           c=CENTRAL_SPOT_COLOUR, alpha=CENTRAL_SPOT_ALPHA, zorder=3)\n",
    "        if len(used_predicted_pts):\n",
    "            ax_pts.scatter(used_predicted_pts[:, 0], used_predicted_pts[:, 1],\n",
    "                           s=PARTIAL_PRED_SIZE, marker=PARTIAL_PRED_MARKER,\n",
    "                           c=PARTIAL_PRED_COLOUR, linewidths=1.3, zorder=4)\n",
    "\n",
    "        ax_leg.axis(\"off\")\n",
    "        if SHOW_LEGEND:\n",
    "            leg1 = ax_leg.legend(\n",
    "                handles=build_overlay_legend_handles(show_other=not suppress_other),\n",
    "                loc=\"upper left\",\n",
    "                framealpha=0.9,\n",
    "                fontsize=8,\n",
    "                title=\"Overlay legend\",\n",
    "                title_fontsize=9,\n",
    "            )\n",
    "            ax_leg.add_artist(leg1)\n",
    "            ax_leg.legend(\n",
    "                handles=build_points_legend_handles(),\n",
    "                loc=\"lower left\",\n",
    "                framealpha=0.9,\n",
    "                fontsize=8,\n",
    "                title=\"Spots legend\",\n",
    "                title_fontsize=9,\n",
    "            )\n",
    "\n",
    "        base = os.path.splitext(os.path.basename(image_d_path))[0]\n",
    "        combined_path = os.path.join(out_dir, f\"{base}_combined.png\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(combined_path, dpi=200)\n",
    "        plt.close(fig)\n",
    "\n",
    "    return {\n",
    "        \"filename\": os.path.basename(image_d_path),\n",
    "        \"category\": category,\n",
    "        \"reason\": reason,\n",
    "        \"model_ok\": bool(model and model.get(\"ok\", False)),\n",
    "        \"model_reason\": \"\" if model is None else model.get(\"reason\", \"\"),\n",
    "        \"r_o1_norm\": \"\" if not (model and model.get(\"ok\", False)) else float(model[\"r_o1\"]),\n",
    "        \"r_o3_norm\": \"\" if not (model and model.get(\"ok\", False)) else float(model[\"r_o3\"]),\n",
    "        \"scale_px\": float(scale),\n",
    "        \"normalise_by\": NORMALIZE_BY,\n",
    "        \"used_fallback\": bool(used_fallback),\n",
    "        \"radii_norm_all\": radii_norm_all,\n",
    "        \"radii_px_all\": radii_px_all,\n",
    "        \"radii_norm_plotted\": radii_norm_plotted,\n",
    "        \"radii_px_plotted\": radii_px_plotted,\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Excel writer\n",
    "# ============================================================\n",
    "\n",
    "def write_excel(results, out_root):\n",
    "    xlsx_path = os.path.join(out_root, \"dp_categories.xlsx\")\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"categories\"\n",
    "\n",
    "    headers = [\n",
    "        \"filename\", \"category\", \"reason\",\n",
    "        \"model_ok\", \"model_reason\",\n",
    "        \"r_o1_norm\", \"r_o3_norm\",\n",
    "        \"o1_tol_frac\", \"o3_tol_frac\",\n",
    "        \"scale_px\", \"normalise_by\", \"used_fallback\",\n",
    "        \"radii_norm_all\", \"radii_px_all\",\n",
    "        \"radii_norm_plotted\", \"radii_px_plotted\",\n",
    "    ]\n",
    "    ws.append(headers)\n",
    "\n",
    "    for r in results:\n",
    "        ws.append([\n",
    "            r[\"filename\"],\n",
    "            r[\"category\"],\n",
    "            r[\"reason\"],\n",
    "            int(bool(r[\"model_ok\"])),\n",
    "            r.get(\"model_reason\", \"\"),\n",
    "            \"\" if r.get(\"r_o1_norm\", \"\") == \"\" else float(r[\"r_o1_norm\"]),\n",
    "            \"\" if r.get(\"r_o3_norm\", \"\") == \"\" else float(r[\"r_o3_norm\"]),\n",
    "            float(O1_MATCH_FRAC),\n",
    "            float(O3_MATCH_FRAC),\n",
    "            float(r.get(\"scale_px\", 0.0)),\n",
    "            r.get(\"normalise_by\", NORMALIZE_BY),\n",
    "            int(bool(r.get(\"used_fallback\", False))),\n",
    "            \",\".join(f\"{x:.5f}\" for x in r.get(\"radii_norm_all\", [])),\n",
    "            \",\".join(f\"{x:.2f}\" for x in r.get(\"radii_px_all\", [])),\n",
    "            \",\".join(f\"{x:.5f}\" for x in r.get(\"radii_norm_plotted\", [])),\n",
    "            \",\".join(f\"{x:.2f}\" for x in r.get(\"radii_px_plotted\", [])),\n",
    "        ])\n",
    "\n",
    "    header_font = Font(bold=True)\n",
    "    for col_idx in range(1, len(headers) + 1):\n",
    "        cell = ws.cell(row=1, column=col_idx)\n",
    "        cell.font = header_font\n",
    "        cell.alignment = Alignment(horizontal=\"center\", vertical=\"center\", wrap_text=True)\n",
    "\n",
    "    widths = {\n",
    "        \"A\": 22, \"B\": 24, \"C\": 75, \"D\": 10, \"E\": 30,\n",
    "        \"F\": 12, \"G\": 12, \"H\": 10, \"I\": 10,\n",
    "        \"J\": 12, \"K\": 12, \"L\": 12,\n",
    "        \"M\": 34, \"N\": 28, \"O\": 34, \"P\": 28\n",
    "    }\n",
    "    for col, w in widths.items():\n",
    "        ws.column_dimensions[col].width = w\n",
    "\n",
    "    wb.save(xlsx_path)\n",
    "    return xlsx_path\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Grid chart (d_<row>_<col> ordering) + colourblind-friendly palette\n",
    "# ============================================================\n",
    "\n",
    "def parse_row_col_from_filename(filename: str) -> Optional[Tuple[int, int]]:\n",
    "    base = os.path.basename(filename)\n",
    "    m = re.search(r\"^d_(\\d+)_(\\d+)_\", base)  # works for d_0_5_d.png etc.\n",
    "    if not m:\n",
    "        return None\n",
    "    return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "\n",
    "def grid_label_for_category(cat: str) -> str:\n",
    "    if cat == CAT_O3_ONLY:\n",
    "        return \"O3\"\n",
    "    if cat == CAT_O1_ONLY:\n",
    "        return \"O1\"\n",
    "    if cat == CAT_O1_O3:\n",
    "        return \"BOTH\"\n",
    "    if cat == TIMEOUT_CATEGORY:\n",
    "        return \"TIMEOUT\"\n",
    "    if cat == CAT_HEX_NOT_O1O3:\n",
    "        return \"OTHER\"\n",
    "    return \"NONE\"\n",
    "\n",
    "\n",
    "def _hex_to_rgb01(h):\n",
    "    h = h.lstrip(\"#\")\n",
    "    return np.array([int(h[i:i+2], 16) for i in (0, 2, 4)], dtype=float) / 255.0\n",
    "\n",
    "def _rgb01_to_hex(rgb):\n",
    "    rgb = np.clip(np.array(rgb) * 255.0, 0, 255).astype(int)\n",
    "    return \"#{:02X}{:02X}{:02X}\".format(rgb[0], rgb[1], rgb[2])\n",
    "\n",
    "\n",
    "def build_grid_chart(results: List[Dict], out_root: str) -> str:\n",
    "    items = []\n",
    "    for r in results:\n",
    "        rc = parse_row_col_from_filename(r[\"filename\"])\n",
    "        if rc is None:\n",
    "            continue\n",
    "        row, col = rc\n",
    "        items.append((row, col, grid_label_for_category(r[\"category\"]), r[\"filename\"]))\n",
    "\n",
    "    if not items:\n",
    "        return \"\"\n",
    "\n",
    "    rows = sorted({it[0] for it in items})\n",
    "    row_to_cols = {}\n",
    "    for row in rows:\n",
    "        cols = sorted({c for (rr, c, _, _) in items if rr == row})\n",
    "        row_to_cols[row] = cols\n",
    "\n",
    "    max_cols = max(len(row_to_cols[row]) for row in rows)\n",
    "\n",
    "    # Okabe–Ito style colourblind-friendly palette:\n",
    "    C_NONE  = \"#FFFFFF\"\n",
    "    C_O1    = \"#0072B2\"  # blue\n",
    "    C_O3    = \"#D55E00\"  # vermillion\n",
    "    C_OTHER = \"#009E73\"  # bluish green\n",
    "    C_TO    = \"#7F7F7F\"  # grey\n",
    "    C_MISS  = \"#F2F2F2\"  # missing slot\n",
    "\n",
    "    C_BOTH = _rgb01_to_hex(0.5 * (_hex_to_rgb01(C_O1) + _hex_to_rgb01(C_O3)))\n",
    "\n",
    "    label_to_code = {\n",
    "        \"NONE\": 0,\n",
    "        \"O1\": 1,\n",
    "        \"O3\": 2,\n",
    "        \"BOTH\": 3,\n",
    "        \"OTHER\": 4,\n",
    "        \"TIMEOUT\": 5,\n",
    "    }\n",
    "\n",
    "    colors = [C_NONE, C_O1, C_O3, C_BOTH, C_OTHER, C_TO]\n",
    "    cmap = ListedColormap(colors)\n",
    "    cmap.set_bad(C_MISS)\n",
    "\n",
    "    bounds = np.arange(-0.5, len(colors) + 0.5, 1.0)\n",
    "    norm = BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "    grid = np.full((len(rows), max_cols), np.nan, dtype=float)\n",
    "    text = np.full((len(rows), max_cols), \"\", dtype=object)\n",
    "    col_ids = np.full((len(rows), max_cols), \"\", dtype=object)\n",
    "\n",
    "    lookup = {(row, col): label for (row, col, label, _) in items}\n",
    "\n",
    "    for i, row in enumerate(rows):\n",
    "        cols = row_to_cols[row]\n",
    "        for j, col in enumerate(cols):\n",
    "            label = lookup.get((row, col), \"NONE\")\n",
    "            grid[i, j] = float(label_to_code[label])\n",
    "            text[i, j] = label\n",
    "            col_ids[i, j] = str(col)\n",
    "\n",
    "    fig_w = max(8.0, 0.55 * max_cols)\n",
    "    fig_h = max(3.5, 0.55 * len(rows))\n",
    "    fig, ax = plt.subplots(figsize=(fig_w, fig_h))\n",
    "\n",
    "    ax.imshow(grid, interpolation=\"nearest\", aspect=\"auto\", cmap=cmap, norm=norm)\n",
    "    ax.set_title(\"O1/O3 grid (rows=d_<row>_xx, cols increasing)\")\n",
    "\n",
    "    ax.set_yticks(np.arange(len(rows)))\n",
    "    ax.set_yticklabels([str(r) for r in rows])\n",
    "    ax.set_ylabel(\"row index (first number)\")\n",
    "\n",
    "    ax.set_xticks(np.arange(max_cols))\n",
    "    ax.set_xticklabels([str(i) for i in range(max_cols)])\n",
    "    ax.set_xlabel(\"column position within row (sorted by xx)\")\n",
    "\n",
    "    for i in range(len(rows)):\n",
    "        for j in range(max_cols):\n",
    "            if np.isnan(grid[i, j]):\n",
    "                continue\n",
    "            ax.text(j, i, f\"{text[i, j]}\\n{col_ids[i, j]}\",\n",
    "                    ha=\"center\", va=\"center\", fontsize=8)\n",
    "\n",
    "    ax.set_xticks(np.arange(-.5, max_cols, 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-.5, len(rows), 1), minor=True)\n",
    "    ax.grid(which=\"minor\", linestyle=\"-\", linewidth=0.6)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "    legend_handles = [\n",
    "        Patch(facecolor=C_NONE,  edgecolor=\"black\", label=\"NONE\"),\n",
    "        Patch(facecolor=C_O1,    edgecolor=\"black\", label=\"O1\"),\n",
    "        Patch(facecolor=C_O3,    edgecolor=\"black\", label=\"O3\"),\n",
    "        Patch(facecolor=C_BOTH,  edgecolor=\"black\", label=\"BOTH\"),\n",
    "        Patch(facecolor=C_OTHER, edgecolor=\"black\", label=\"OTHER\"),\n",
    "        Patch(facecolor=C_TO,    edgecolor=\"black\", label=\"TIMEOUT\"),\n",
    "        Patch(facecolor=C_MISS,  edgecolor=\"black\", label=\"MISSING\"),\n",
    "    ]\n",
    "    ax.legend(handles=legend_handles, loc=\"upper right\", framealpha=0.95, fontsize=8)\n",
    "\n",
    "    out_path = os.path.join(out_root, \"o1_o3_grid.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=200)\n",
    "    plt.close(fig)\n",
    "    return out_path\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Run pipeline\n",
    "# ============================================================\n",
    "\n",
    "def process_checkpoint_figures(image_glob=IMAGE_GLOB, out_root_base=OUT_ROOT_BASE):\n",
    "    paths = sorted(glob.glob(image_glob))\n",
    "    if not paths:\n",
    "        print(\"No images found:\", image_glob)\n",
    "        return\n",
    "\n",
    "    first = paths[0]\n",
    "    parent_dir = os.path.dirname(first)\n",
    "    run_dir = os.path.dirname(parent_dir)\n",
    "    run_name = os.path.basename(run_dir)\n",
    "\n",
    "    out_root = os.path.join(out_root_base, run_name)\n",
    "    os.makedirs(out_root, exist_ok=True)\n",
    "\n",
    "    for cat in [CAT_NO_HEX, CAT_HEX_NOT_O1O3, CAT_O1_ONLY, CAT_O3_ONLY, CAT_O1_O3, TIMEOUT_CATEGORY]:\n",
    "        os.makedirs(os.path.join(out_root, cat), exist_ok=True)\n",
    "\n",
    "    model = build_o3_o1_model(paths)\n",
    "\n",
    "    results = []\n",
    "    for path in tqdm(paths, desc=\"Processing (RANSAC hex + O1/O3)\", leave=True):\n",
    "        img_bgr = cv2.imread(path)\n",
    "        if img_bgr is None:\n",
    "            continue\n",
    "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "        results.append(analyse_one(img_rgb, path, out_root, model))\n",
    "\n",
    "    report_path = os.path.join(out_root, \"dp_categories.txt\")\n",
    "    with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"filename\\tcategory\\n\")\n",
    "        for r in results:\n",
    "            f.write(f\"{r['filename']}\\t{r['category']}\\n\")\n",
    "\n",
    "    xlsx_path = write_excel(results, out_root)\n",
    "    grid_path = build_grid_chart(results, out_root)\n",
    "\n",
    "    print(\"Wrote:\", report_path)\n",
    "    print(\"Wrote:\", xlsx_path)\n",
    "    if grid_path:\n",
    "        print(\"Wrote:\", grid_path)\n",
    "    print(\"Model:\", model)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_checkpoint_figures()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
