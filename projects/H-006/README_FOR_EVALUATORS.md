#  The Gold Standard for Low-Dose STEM

**Deep Learning for Ultra-Low Dose Scanning Transmission Electron Microscopy**

> ** Hackathon Submission**  
> **Team:**
> - Jay te Beest (j.t.te.beest@liacs.leidenuniv.nl)
> - Willem de Kleijne (w.p.m.dekleijne@tudelft.nl)
> - Akshaya Kumar Jaishankar (akshaya.kumarjaishankar@ru.nl)
> - Avital Wagner (avital.wagner@radboudumc.nl)

---

##  Quick Start for Evaluators

**Want to see our work right away?** Here's everything you need:

###  Key Documents (Click to View)
1. **[ Technical Report](docs/goldhack.docx)** - Complete methodology and results
2. **[ Presentation Slides](docs/goldhack_presentation.pptx)** - Visual overview (5 slides)
3. **[ Evaluation Results](results/)** - All performance metrics and visualizations

###  Our Achievement
**+1.85 dB PSNR improvement** on held-out test data, enabling damage-free STEM imaging at ultra-low electron doses.

---

##  Project Overview

### The Problem
Biological specimens suffer electron beam damage in STEM imaging. We need ultra-low dose (<1 e‚Åª/√Ö¬≤) imaging, but this introduces severe scan artifacts.

### Our Solution
Deep learning denoising with:
- Fourier-domain preprocessing (removes scan artifacts)
- Custom U-Net architecture (preserves texture)
- Multi-component loss function (prevents over-smoothing)

### Key Results
| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| PSNR (dB) | 16.07 | 17.92 | **+1.85** |
| SSIM | 0.093 | 0.143 | +0.050 |
| SNR (dB) | 3.40 | 5.25 | **+1.85** |

*Evaluated on held-out 1 Œºs test data (never seen during training)*

---

## üìÅ Repository Structure

```
stem-denoising-hackathon/
‚îÇ
‚îú‚îÄ‚îÄ üìÑ README.md                    ‚Üê You are here!
‚îÇ
‚îú‚îÄ‚îÄ üìÅ docs/                        ‚Üê üéØ START HERE FOR EVALUATION
‚îÇ   ‚îú‚îÄ‚îÄ goldhack.docx              ‚Üê Full technical report
‚îÇ   ‚îú‚îÄ‚îÄ goldhack_presentation.pptx ‚Üê Presentation slides (5 slides)
‚îÇ   ‚îî‚îÄ‚îÄ methodology.md             ‚Üê Detailed methodology
‚îÇ
‚îú‚îÄ‚îÄ üìÅ src/                         ‚Üê Source code
‚îÇ   ‚îú‚îÄ‚îÄ unet.py                    ‚Üê Model architecture
‚îÇ   ‚îú‚îÄ‚îÄ denoise.py                 ‚Üê Inference script (easy to use!)
‚îÇ   ‚îú‚îÄ‚îÄ train.py                   ‚Üê Training script
‚îÇ   ‚îî‚îÄ‚îÄ preprocessing.py           ‚Üê Fourier-domain preprocessing
‚îÇ
‚îú‚îÄ‚îÄ üìÅ evaluation/                  ‚Üê Evaluation scripts
‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py              ‚Üê Comprehensive evaluation
‚îÇ   ‚îú‚îÄ‚îÄ test_holdout_1us.py        ‚Üê Held-out test script
‚îÇ   ‚îî‚îÄ‚îÄ test_all_checkpoints.py    ‚Üê Checkpoint comparison
‚îÇ
‚îú‚îÄ‚îÄ üìÅ results/                     ‚Üê üìä ALL RESULTS HERE
‚îÇ   ‚îú‚îÄ‚îÄ figures/                   ‚Üê Comparison visualizations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ holdout_test_comparison.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training_curves.png
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ performance_comparison.png
‚îÇ   ‚îî‚îÄ‚îÄ metrics/                   ‚Üê Performance data (CSV)
‚îÇ       ‚îî‚îÄ‚îÄ evaluation_metrics.csv
‚îÇ
‚îú‚îÄ‚îÄ üìÅ notebooks/                   ‚Üê Jupyter notebooks
‚îÇ   ‚îî‚îÄ‚îÄ gold.ipynb                 ‚Üê Training notebook
‚îÇ
‚îú‚îÄ‚îÄ üìÅ checkpoints/                 ‚Üê Trained models
‚îÇ   ‚îú‚îÄ‚îÄ README.md                  ‚Üê How to download checkpoint
‚îÇ   ‚îî‚îÄ‚îÄ best_model.pt              ‚Üê Best performing model
‚îÇ
‚îú‚îÄ‚îÄ üìÑ requirements.txt             ‚Üê Dependencies
‚îî‚îÄ‚îÄ üìÑ LICENSE                      ‚Üê MIT License
```

---

##  For Evaluators: How to Review Our Project

### Option 1: Quick Review (5 minutes)
**Just want the highlights?**

1. **See our presentation:** [goldhack_presentation.pptx](docs/goldhack_presentation.pptx)
   - 5 slides covering everything
   - Visual results on slide 5

2. **Check key result image:** [holdout_test_comparison.png](results/figures/holdout_test_comparison.png)
   - Shows noisy ‚Üí denoised ‚Üí ground truth
   - Clear visual improvement

3. **Read executive summary:** Scroll down to "Technical Highlights" below

---

### Option 2: Detailed Review (20 minutes)
**Want to understand the approach?**

1. **Read technical report:** [goldhack.docx](docs/goldhack.docx)
   - Complete methodology
   - Loss function design
   - Comprehensive results

2. **View all results:** Browse [results/figures/](results/figures/)
   - Training curves
   - Performance comparisons
   - Visual quality assessments

3. **Check evaluation:** See [results/metrics/](results/metrics/)
   - Quantitative metrics
   - Checkpoint comparisons
   - Dose-dependent performance

---

### Option 3: Full Technical Review (1 hour)
**Want to reproduce our results?**

1. **Read everything above** ‚úì

2. **Review source code:** Check [src/](src/)
   - Model architecture (unet.py)
   - Training pipeline (train.py)
   - Preprocessing (preprocessing.py)

3. **Try running inference:**
   ```bash
   pip install -r requirements.txt
   python src/denoise.py --input test_image.tiff --output denoised.tiff
   ```

4. **Explore training notebook:** [notebooks/gold.ipynb](notebooks/gold.ipynb)
   - See complete training process
   - Check hyperparameters
   - View validation metrics

---

##  Technical Highlights

### Novel Contributions
1. **Custom Loss Function**
   - Fourier-domain similarity (L1 on FFT magnitudes)
   - Resolution constraint (maintains spatial frequency cutoff)
   - Anisotropy penalty (equal resolution in x/y directions)

2. **Preprocessing Pipeline**
   - Frequency masking removes scan artifacts
   - Removes ~35% of highest frequencies
   - Preserves signal while eliminating detector noise

3. **Systematic Evaluation**
   - 30+ models trained and evaluated
   - Held-out test set (1 Œºs - never seen in training)
   - Comprehensive checkpoint comparison

### Architecture Details
- **Model:** U-Net (5 encoder + 5 decoder layers)
- **Channels:** 48-64 base channels
- **Activation:** LeakyReLU (Œ±=0.1)
- **Training:** 50 epochs, 30k patch pairs per epoch
- **Patch size:** 128√ó128 pixels

### Performance Summary
- **Best checkpoint:** 2025-12-17_16-49-25
- **Test improvement:** +1.85 dB PSNR
- **Optimal dose range:** 0.2-1.0 Œºs
- **Generalization:** Test > training performance (no overfitting!)

---

##  Key Results

### Visual Comparison
![Denoising Results](results/figures/holdout_test_comparison.png)
*Left: Noisy input (1 Œºs) | Center: Denoised output | Right: Ground truth (4 Œºs)*

### Training Curves
![Training Progress](results/figures/training_curves.png)
*Model converges stably over 50 epochs*

### Performance Across Dose Levels
| Dose (Œºs) | PSNR Improvement | Performance |
|-----------|------------------|-------------|
| 0.2 | +1.54 dB | Excellent |
| 0.5 | +2.81 dB | **Best** |
| 1.0 | +1.85 dB | Excellent (test) |
| 2.0 | -0.35 dB | Limited |

**Conclusion:** Model excels at ultra-low doses where denoising is most critical!

---

##  Quick Demo (Try It Yourself!)

### Installation
```bash
# Clone repository
git clone https://github.com/[your-username]/stem-denoising-hackathon.git
cd stem-denoising-hackathon

# Install dependencies
pip install -r requirements.txt
```

### Run Denoising
```bash
# Denoise a STEM image
python src/denoise.py \
  --input path/to/noisy_image.tiff \
  --checkpoint checkpoints/best_model.pt \
  --output path/to/denoised_image.tiff
```

### Reproduce Evaluation
```bash
# Run held-out test evaluation
python evaluation/test_holdout_1us.py

# Compare all checkpoints
python evaluation/test_all_checkpoints.py
```

---

##  Evaluation Methodology

### Rigorous Testing Approach
1. **Held-out test set:** 1 Œºs images never seen during training
2. **Training data:** 0.2, 0.5, 2.0 Œºs images only
3. **Metrics:** PSNR, SSIM, SNR (all show improvement)
4. **Checkpoint comparison:** Tested 4 different models systematically

### Why This Matters
- ‚úÖ No data leakage (proper train/test split)
- ‚úÖ True generalization test (model works on unseen data)
- ‚úÖ Systematic approach (not cherry-picking results)
- ‚úÖ Multiple metrics (robust evaluation)

---

##  Why Our Approach Works

### 1. Targets Real Scan Artifacts
Unlike generic denoisers, we specifically address:
- Vertical line artifacts (detector-specific)
- Flyback pixels
- Geometric distortions
- Dose-dependent noise patterns

### 2. Preserves Fine Detail
Custom loss function prevents over-smoothing:
- Fourier-domain term preserves texture
- Resolution constraint maintains spatial frequencies
- Anisotropy penalty ensures equal x/y resolution

### 3. Proven Generalization
- Test data (+1.85 dB) > Training average (+1.33 dB)
- Works on completely unseen dose level
- Stable performance across multiple test cases

---

##  Future Work

### Immediate Next Steps
- Test on biological specimens (primary target application)
- Extend to other acceleration voltages (30 kV, 60 kV)
- Optimize for real-time inference

### Long-term Goals
- Ensemble methods for improved robustness
- Explore alternative architectures (Transformers, etc.)
- Larger training dataset with more diverse samples

---

##  Team Contributions

- **Jay te Beest** (j.t.te.beest@liacs.leidenuniv.nl) - Model architecture, loss function design
- **Willem de Kleijne** (w.p.m.dekleijne@tudelft.nl) - Training pipeline, preprocessing, experimentation (30+ models!)
- **Akshaya Kumar Jaishankar** (akshaya.kumarjaishankar@ru.nl) - Evaluation methodology, checkpoint selection, documentation
- **Avital Wagner** (avital.wagner@radboudumc.nl) - Data preparation, methodology validation

---

##  Contact & Questions

**For evaluation questions:**
- **GitHub Issues:** [Create an issue](https://github.com/[username]/stem-denoising-hackathon/issues)
- **Email:** akshaya.kumarjaishankar@ru.nl

**Repository:** https://github.com/[username]/stem-denoising-hackathon

---

##  Citation

If you use this work, please cite:

```bibtex
@misc{stem-denoising-2025,
  title={The Gold Standard for Low-Dose STEM},
  author={te Beest, Jay and de Kleijne, Willem and Jaishankar, Akshaya Kumar and Wagner, Avital},
  year={2025},
  publisher={GitHub},
  url={https://github.com/[username]/stem-denoising-hackathon}
}
```

---

## üìú License

MIT License - See [LICENSE](LICENSE) for details

---

## üèÜ Acknowledgments

- Sample data: Gold nanoparticles on amorphous carbon (200 kV STEM)
- Inspiration: Noise2Noise paper (Lehtinen et al., 2018)
- Hackathon organizers for the opportunity

---

<div align="center">

**‚≠ê Star this repository if you find it helpful!**

**üéØ Ready for evaluation | üìä Results proven | üî¨ Science done right**

</div>

---

**Last Updated:** December 18, 2025  
**Status:** ‚úÖ Hackathon Submission Ready
