{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b2b553c9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imports OK\n",
            "Server started and running in the background. Logs are being written to server.log.\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import h5py\n",
        "import sidpy\n",
        "import pyNSID\n",
        "from igor2 import binarywave as igor_binarywave\n",
        "\n",
        "print('Imports OK')\n",
        "!run_server_afm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ffbed46f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_note(note_bytes: bytes | str | None) -> dict:\n",
        "    \"\"\"Parse Igor wave note into a dict with key:value per line.\"\"\"\n",
        "    if note_bytes is None:\n",
        "        return {}\n",
        "    if isinstance(note_bytes, str):\n",
        "        text = note_bytes\n",
        "    else:\n",
        "        text = (\n",
        "            note_bytes\n",
        "            .replace(b\"\\xb0\", b\"\\xc2\\xb0\")  # °\n",
        "            .replace(b\"\\xb5\", b\"\\xc2\\xb5\")  # µ\n",
        "            .decode(errors=\"replace\")\n",
        "        )\n",
        "    note = {}\n",
        "    for line in text.split(\"\\r\"):\n",
        "        s = line.strip()\n",
        "        if not s or \":\" not in s:\n",
        "            continue\n",
        "        k, v = s.split(\":\", 1)\n",
        "        note[k.strip()] = v.strip()\n",
        "    return note\n",
        "\n",
        "\n",
        "def extract_channel_labels(wave: dict, n_channels: int) -> list[str]:\n",
        "    \"\"\"Extract per-channel labels from Igor 'labels' structure if present.\"\"\"\n",
        "    labels: list[str] = []\n",
        "    raw_labels = wave.get(\"labels\", None)\n",
        "\n",
        "    if isinstance(raw_labels, (list, tuple)) and len(raw_labels) >= 3:\n",
        "        candidate = raw_labels[2]\n",
        "        if isinstance(candidate, (list, tuple)) and len(candidate) > 1:\n",
        "            for item in candidate[1:]:\n",
        "                if isinstance(item, (bytes, bytearray)):\n",
        "                    labels.append(item.decode(errors=\"replace\"))\n",
        "                else:\n",
        "                    labels.append(str(item))\n",
        "\n",
        "    if len(labels) < n_channels:\n",
        "        labels += [f\"Channel_{i:03d}\" for i in range(len(labels), n_channels)]\n",
        "\n",
        "    return labels[:n_channels]\n",
        "\n",
        "\n",
        "def build_channel_selection(labels: list[str]) -> list[tuple[int, str, str]]:\n",
        "    \"\"\"Return list of (source_index, output_signal_name, unit) for the 4-channel output.\n",
        "\n",
        "    If a required channel is missing, use src_index = -1 and print a warning.\n",
        "    Downstream code must handle src_index == -1 by writing a placeholder array.\n",
        "    \"\"\"\n",
        "    label_to_idx = {lab: i for i, lab in enumerate(labels)}\n",
        "\n",
        "    required = [\n",
        "        (\"HeightRetrace\",    \"HeightRetrace\",     \"m\"),\n",
        "        (\"AmplitudeRetrace\", \"AmplitudeRetrace\",  \"m\"),\n",
        "        (\"ZSensorRetrace\",   \"DeflectionRetrace\", \"m\"),\n",
        "        (\"PhaseRetrace\",     \"PhaseRetrace\",      \"deg\"),\n",
        "    ]\n",
        "\n",
        "    selection: list[tuple[int, str, str]] = []\n",
        "    missing: list[str] = []\n",
        "\n",
        "    # Always output 4 entries, in required order\n",
        "    for src_label, out_signal, unit in required:\n",
        "        if src_label in label_to_idx:\n",
        "            selection.append((label_to_idx[src_label], out_signal, unit))\n",
        "        else:\n",
        "            missing.append(src_label)\n",
        "            selection.append((-1, out_signal, unit))  # placeholder, still keeps 4 channels\n",
        "\n",
        "    if missing:\n",
        "        print(f\"[IBW WARNING] Missing required channels: {missing}. Labels found: {labels}\")\n",
        "\n",
        "    return selection\n",
        "\n",
        "\n",
        "def make_channel_map_from_selection(selection: list[tuple[int, str, str]], measurement: str = \"Measurement_000\") -> dict:\n",
        "    \"\"\"Make a channel_map containing channels/signals/units/scans/spectra/point_clouds.\"\"\"\n",
        "    cm = {\"channels\": {}, \"spectra\": [], \"point_clouds\": []}\n",
        "    for out_i, (src_i, signal, unit) in enumerate(selection):\n",
        "        ch = f\"Channel_{out_i:03d}\"\n",
        "        cm[\"channels\"][ch] = {\n",
        "            \"src_index\": int(src_i),\n",
        "            \"signal\": str(signal),\n",
        "            \"units\": str(unit),\n",
        "            \"scan\": int(out_i),\n",
        "            \"spectrum\": None,\n",
        "            \"point_cloud\": None,\n",
        "            \"h5\": {\n",
        "                \"measurement\": measurement,\n",
        "                \"signal_group\": str(signal),\n",
        "                \"dataset\": str(signal),\n",
        "            },\n",
        "        }\n",
        "    return cm\n",
        "\n",
        "\n",
        "def channel_map_to_dataset_info(cm: dict) -> list:\n",
        "    ch_names = sorted(cm[\"channels\"].keys(), key=lambda x: int(x.split(\"_\")[1]))\n",
        "    signals = [cm[\"channels\"][c][\"signal\"] for c in ch_names]\n",
        "    units = [cm[\"channels\"][c][\"units\"] for c in ch_names]\n",
        "    scans = [cm[\"channels\"][c][\"scan\"] for c in ch_names]\n",
        "    return [\n",
        "        (\"channels\", ch_names),\n",
        "        (\"signals\", signals),\n",
        "        (\"units\", units),\n",
        "        (\"scans\", scans),\n",
        "        (\"spectra\", cm.get(\"spectra\", [])),\n",
        "        (\"point_clouds\", cm.get(\"point_clouds\", [])),\n",
        "    ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c6975893",
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_one_ibw_to_h5(\n",
        "    ibw_path: str | Path,\n",
        "    out_h5_path: str | Path,\n",
        "    rotate_k: int = 1,\n",
        "    measurement_prefix: str = \"Measurement_\",\n",
        ") -> dict:\n",
        "    \"\"\"Convert a single IBW to an NSID H5 with the 4-channel sample-like output.\"\"\"\n",
        "    ibw_path = Path(ibw_path)\n",
        "    out_h5_path = Path(out_h5_path)\n",
        "    out_h5_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    wave = igor_binarywave.load(str(ibw_path))[\"wave\"]\n",
        "    arr = np.asarray(wave[\"wData\"])\n",
        "    if arr.ndim != 3:\n",
        "        raise ValueError(f\"Expected wData to be 3D (X,Y,C). Got shape={arr.shape}\")\n",
        "\n",
        "    note = parse_note(wave.get(\"note\", None))\n",
        "\n",
        "    n_channels = arr.shape[2]\n",
        "    labels = extract_channel_labels(wave, n_channels)\n",
        "\n",
        "    selection = build_channel_selection(labels)\n",
        "    cm = make_channel_map_from_selection(selection)\n",
        "\n",
        "    # Build sidpy datasets for only the selected 4 channels\n",
        "    data_sets: dict[str, sidpy.Dataset] = {}\n",
        "    for ch_key, meta in cm[\"channels\"].items():\n",
        "        src_i = meta[\"src_index\"]\n",
        "        signal = meta[\"signal\"]\n",
        "        unit = meta[\"units\"]\n",
        "\n",
        "        ds = sidpy.Dataset.from_array(np.rot90(arr[:, :, src_i], k=rotate_k), name=signal)\n",
        "        ds.data_type = \"image\"\n",
        "        ds.quantity = signal\n",
        "        ds.units = unit\n",
        "        ds.title = signal\n",
        "        ds.modality = \"AFM\"\n",
        "\n",
        "        # Spatial dimensions (prefer note, fallback to array shape)\n",
        "        nx = int(note.get(\"ScanPoints\", ds.shape[0]))\n",
        "        ny = int(note.get(\"ScanLines\", ds.shape[1]))\n",
        "        slow = float(note.get(\"FastScanSize\", 1.0)) # swapped\n",
        "        fast = float(note.get(\"SlowScanSize\", 1.0)) # swapped\n",
        "\n",
        "        ds.set_dimension(0, sidpy.Dimension(np.linspace(0, fast, nx), name=\"x\", units=\"m\",\n",
        "                                            quantity=\"Length\", dimension_type=\"spatial\"))\n",
        "        ds.set_dimension(1, sidpy.Dimension(np.linspace(0, slow, ny), name=\"y\", units=\"m\",\n",
        "                                            quantity=\"Length\", dimension_type=\"spatial\"))\n",
        "\n",
        "        ds.metadata[\"source_file\"] = ibw_path.name\n",
        "        ds.metadata[\"source_label\"] = labels[src_i]\n",
        "        ds.metadata[\"note\"] = note\n",
        "\n",
        "        data_sets[ch_key] = ds\n",
        "\n",
        "    # Write NSID H5 in the layout: /Measurement_000/Channel_000/<signal>/<signal>\n",
        "    with h5py.File(out_h5_path, mode=\"w\") as h5:\n",
        "        meas = sidpy.hdf.prov_utils.create_indexed_group(h5, measurement_prefix)\n",
        "\n",
        "        for ch_key, ds in data_sets.items():\n",
        "            ch_grp = meas.create_group(ch_key)\n",
        "            sig_grp = ch_grp.create_group(ds.quantity)\n",
        "            pyNSID.hdf_io.write_nsid_dataset(ds, sig_grp)\n",
        "\n",
        "        h5.flush()\n",
        "\n",
        "    return {\n",
        "        \"ibw\": str(ibw_path),\n",
        "        \"h5\": str(out_h5_path),\n",
        "        \"labels\": labels,\n",
        "        \"channel_map\": cm,\n",
        "        \"dataset_info_preview\": channel_map_to_dataset_info(cm),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0934fe9c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_folder_ibw_to_h5(in_folder: str | Path, out_folder: str | Path | None = None) -> None:\n",
        "    in_folder = Path(in_folder)\n",
        "    if out_folder is None:\n",
        "        out_folder = in_folder.with_name(in_folder.name + \"_h5\")\n",
        "    else:\n",
        "        out_folder = Path(out_folder)\n",
        "    out_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    ibw_files = sorted(in_folder.glob(\"*.ibw\"))\n",
        "    print(f\"Found {len(ibw_files)} .ibw files in: {in_folder}\")\n",
        "    print(f\"Writing .h5 files to: {out_folder}\")\n",
        "\n",
        "    ok, fail = 0, 0\n",
        "    for ibw in ibw_files:\n",
        "        try:\n",
        "            out_h5 = out_folder / f\"{ibw.stem}.h5\"\n",
        "            info = convert_one_ibw_to_h5(ibw, out_h5)\n",
        "            ok += 1\n",
        "            print(f\"[OK] {ibw.name} -> {out_h5.name}\")\n",
        "            # Preview the dataset-info format the server expects:\n",
        "            if ok == 1:\n",
        "                print(\"Preview (server-style):\")\n",
        "                print(info[\"dataset_info_preview\"])\n",
        "        except Exception as e:\n",
        "            fail += 1\n",
        "            print(f\"[FAIL] {ibw.name}: {type(e).__name__}: {e}\")\n",
        "\n",
        "    print(f\"\\nDone. Success: {ok}, Failed: {fail}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "75453ac4",
      "metadata": {},
      "outputs": [],
      "source": [
        "import Pyro5.api\n",
        "def test_with_mic_server(h5_filename: str, uri: str = \"PYRO:microscope.server@localhost:9092\", data_path: str = \"data/AFM\"):\n",
        "\n",
        "    mic_server = Pyro5.api.Proxy(uri)\n",
        "\n",
        "    mic_server.initialize_microscope(\"AFM\", data_path=\"/\".join([\"..\", \"..\", data_path, h5_filename]))\n",
        "    mic_server.setup_microscope(data_source=\"Compound_Dataset_1\")\n",
        "    return mic_server.get_dataset_info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ccac9316",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2 .ibw files in: last_batch\n",
            "Writing .h5 files to: last_batch_h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\wongu\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pyNSID\\io\\hdf_utils.py:381: FutureWarning: validate_h5_dimension may be removed in a future version\n",
            "  warn('validate_h5_dimension may be removed in a future version',\n",
            "c:\\Users\\wongu\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pyNSID\\io\\hdf_utils.py:381: FutureWarning: validate_h5_dimension may be removed in a future version\n",
            "  warn('validate_h5_dimension may be removed in a future version',\n",
            "c:\\Users\\wongu\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pyNSID\\io\\hdf_utils.py:381: FutureWarning: validate_h5_dimension may be removed in a future version\n",
            "  warn('validate_h5_dimension may be removed in a future version',\n",
            "c:\\Users\\wongu\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pyNSID\\io\\hdf_utils.py:381: FutureWarning: validate_h5_dimension may be removed in a future version\n",
            "  warn('validate_h5_dimension may be removed in a future version',\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] cufoil_high.ibw -> cufoil_high.h5\n",
            "Preview (server-style):\n",
            "[('channels', ['Channel_000', 'Channel_001', 'Channel_002', 'Channel_003']), ('signals', ['HeightRetrace', 'AmplitudeRetrace', 'DeflectionRetrace', 'PhaseRetrace']), ('units', ['m', 'm', 'm', 'deg']), ('scans', [0, 1, 2, 3]), ('spectra', []), ('point_clouds', [])]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\wongu\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pyNSID\\io\\hdf_utils.py:381: FutureWarning: validate_h5_dimension may be removed in a future version\n",
            "  warn('validate_h5_dimension may be removed in a future version',\n",
            "c:\\Users\\wongu\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pyNSID\\io\\hdf_utils.py:381: FutureWarning: validate_h5_dimension may be removed in a future version\n",
            "  warn('validate_h5_dimension may be removed in a future version',\n",
            "c:\\Users\\wongu\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pyNSID\\io\\hdf_utils.py:381: FutureWarning: validate_h5_dimension may be removed in a future version\n",
            "  warn('validate_h5_dimension may be removed in a future version',\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] cufoil_low.ibw -> cufoil_low.h5\n",
            "\n",
            "Done. Success: 2, Failed: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\wongu\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pyNSID\\io\\hdf_utils.py:381: FutureWarning: validate_h5_dimension may be removed in a future version\n",
            "  warn('validate_h5_dimension may be removed in a future version',\n"
          ]
        }
      ],
      "source": [
        "1# --- EDIT THESE ---\n",
        "IN_FOLDER = r\"last_batch\"              # folder containing .ibw files\n",
        "OUT_FOLDER = r\"last_batch_h5\"  # output folder for .h5\n",
        "\n",
        "convert_folder_ibw_to_h5(IN_FOLDER, OUT_FOLDER)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
