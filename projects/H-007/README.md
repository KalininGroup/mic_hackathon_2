# AFM-SPARK  
**Sparse Patch Assisted Reconstruction Kernel for AFM Super-Resolution**

AFM-SPARK is a system-specific super-resolution framework for Atomic Force Microscopy (AFM) imaging.  
The method reconstructs a global high-resolution (HR) AFM image from a fast low-resolution (LR) scan and a small number of selectively acquired HR patches, significantly reducing acquisition time while preserving nanoscale fidelity.

---

## Motivation

Atomic Force Microscopy provides nanometer-scale surface characterization, but high-resolution imaging is intrinsically slow due to point-by-point raster scanning. In practice, fast AFM scans are often required to cover wide areas, resulting in low-resolution images that miss critical nanoscale features.

Recent AFM super-resolution approaches rely on supervised learning using artificially down-sampled HR images. However, such datasets fail to capture **system-specific imaging artifacts** introduced by real AFM acquisition conditions, such as scan-rate–dependent distortions.

AFM-SPARK addresses this limitation by explicitly incorporating **experimental intuition, physics-based simulation, and sparse high-resolution observations** into the reconstruction process.

---

## Key Idea

> **A few informative high-resolution patches can "spark" the reconstruction of a full high-resolution AFM image.**

AFM-SPARK reconstructs a global HR image using:
- One global LR AFM scan
- A small number of selectively chosen HR patches
- A conditional flow-matching model trained on aligned LR–HR patch pairs

This formulation treats AFM super-resolution as a **system- and instance-specific inference problem**, rather than a generic image upscaling task.

---

## Workflow Overview

1. **Data Generation (DTM-based Simulation)**  
   - A ground-truth AFM image is imported into a Digital Twin Microscopy (DTM) platform.
   - Low-resolution images are generated by virtual re-scanning the surface at higher scan rates.
   - This ensures perfectly aligned LR–HR pairs while preserving acquisition-specific artifacts.

2. **Patch Selection from LR Image**  
   - The LR image is divided into an 8 × 8 grid.
   - For each patch, five indicators are computed:
     - Mean
     - Standard deviation
     - Gradient magnitude
     - Laplacian
     - Fourier-domain texture indicator
   - A farthest-first strategy is used to select diverse and information-rich patches, with partial weighting on gradient (slope) and Laplacian (curvature).

3. **Training Pair Construction**  
   - Selected LR patches are paired with HR patches at identical spatial coordinates.
   - Only a small subset of patches (e.g., 20) is used for training.
   - Remaining patches are reserved for validation.

4. **Model Training: TinyUNetFlow**  
   - A conditional flow-matching framework is adopted.
   - At each iteration, an intermediate state is sampled as:
     ```
     x_t = (1 - t) x_0 + t x_1
     ```
   - The model learns the velocity field that transports LR patches to HR patches.
   - Loss terms include:
     - Mean Squared Error (flow matching)
     - Gradient loss
     - Laplacian loss

5. **Inference and Reconstruction**  
   - The trained model is applied to all LR patches.
   - Reconstructed HR patches are stitched to form a global HR AFM image.

---

## `DTM_HR_to_LR.py`

`DTM_HR_to_LR.py` loads AFM image data stored in a single `.h5` file and uses the **AFM Digital Twin (DTM)** to generate **low-resolution (LR)** AFM images from an original **high-resolution (HR) ground-truth** image. The LR data are synthesized by simulating faster-scan conditions via **scan-rate scaling** and **downsampling of scan lines / points**.

### How to use

1. Save AFM data in a DTM-compatible `.h5` format under the `h5_files/` directory.
2. Set `file_name` to load the target `.h5` file.
3. Adjust `SCAN_RATE_FACTOR` to simulate a faster scan-rate environment and generate corresponding LR outputs.

> In this project, simulation data were collected at **4×** and **8×** scan-rate conditions.

### Resolution settings (fast-scan assumption)

To reflect typical AFM fast-scan settings, the number of **scan lines** and **points per line** is reduced to **1/4** of the original (i.e., line/point decimation by a factor of 4).



# AFM-SPARK

Lightweight flow-matching super-resolution pipeline for AFM data. Entry points: `run.py` (training) and `Inference.py` (inference).

## Setup
```bash
pip install torch numpy scipy matplotlib tqdm
```
Use a CUDA build of PyTorch to enable GPU acceleration.

## Data layout
- Place HR/LR npy pairs under `data/`, e.g., `sample_0.5_HR.npy` and `sample_2.0_LR.npy`.
- Paths are relative to the repo root; run scripts from the project root.

## Training (`run.py`)
Example:
```bash
python run.py \
  --hr data/Graphite.h5_0.5_HR.npy \
  --lr data/Graphite.h5_2.0_LR.npy \
  --n_list 2,4 \
  --n_select 20 \
  --out_dir runs/exp1
```
Key options:
- `--hr` / `--lr`: HR/LR npy paths
- `--n_list`: comma-separated patch counts to train (e.g., `2,4,8`)
- `--n_select`: number of patches selected from LR
- `--grid`: patch grid split (default 8 ⇒ patch size = side/8)
- `--steps`: flow-matching dt steps (default 200)
- `--K_t`: t samples per patch (default 4)
- `--amp`: enable torch.cuda.amp

Outputs:
- `runs/<timestamp>/config.json`, `n*/weight.pt`, `n*/metrics.csv`, `n*/loss.png`

## Inference (`Inference.py`)
Use a training output root (`runs/<timestamp>`) plus HR/LR npy to generate SR via sliding-window Euler integration.
```bash
python Inference.py \
  --weights runs/exp1 \
  --hr data/Graphite.h5_0.5_HR.npy \
  --lr data/Graphite.h5_2.0_LR.npy \
  --steps_infer 10 \
  --batch_size 64
```
Outputs:
- Under `runs/<timestamp>/inference/`: HR/LR/SR comparison PNGs and feature mask PNGs.

## Modules
- `src/util.py`: patch split/feature/selection, Hann window
- `src/data.py`: HR/LR loading, normalization, patch pair prep
- `src/unet.py`: TinyUNetFlow model
- `src/flowmatching.py`: flow-matching loss and helpers

## Notes
- If HR/LR shapes differ, LR is resized to HR via nearest neighbor by default (`--interp_order` to change).
- Device is chosen via `torch.cuda.is_available()`. Set `CUDA_VISIBLE_DEVICES` as needed.



## Experimental Setup

- **Sample**: Graphite  
- **Instrument**: AFM MFP-3D (Asylum Research)  
- **Ground Truth**:  
  - 80 × 80 µm HeightRetrace image  
  - 512 × 512 pixels  
- **Low-Resolution Generation**:  
  - Virtual re-scanning with varied scan rates using DTM

---

## Key Contributions

- Introduces a **sparse-patch–driven AFM super-resolution framework**
- Avoids naive down-sampling by using **physics-based DTM simulations**
- Enables **instance-specific reconstruction** from a single AFM image
- Reduces experimental acquisition time while preserving image fidelity

---

## Limitations and Future Work

- Patch selection is currently rule-based; learning-based selection is a promising extension.
- LR images are generated only by scan-speed modulation.
  - Future work will include other degradation mechanisms such as:
    - Tip shape variation
    - PID noise
    - Drift
    - Line artifacts
- Incorporating degradation parameters as conditional inputs may further improve robustness for real experimental data.

---

## Project Context

This project was developed as part of **Microscopy Hackathon: AFM-SPARK**,  
focusing on machine-learning–enabled reconstruction techniques for AFM imaging.

---

## Authors

Youngwoo Choi  
Seunghwan Ryu  
Junho Yang  
Jihui Won  
Sanggil Park  
Chaeyul Kang
